{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9695e434-49b9-475c-a61b-039e04be7f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing data for orientation: Front\n",
      "Processing data for orientation: Up\n",
      "Processing data for orientation: Down\n",
      "Preprocessing complete for all orientations.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "\n",
    "# Set base path to the dataset and target image size\n",
    "base_path = \"C:\\\\Users\\\\devar\\\\Downloads\\\\IIITM_Face_Emotion_dataset-20240908T082705Z-001\\\\IIITM_Face_Emotion_dataset\"\n",
    "target_size = (224, 224)\n",
    "\n",
    "# Define emotion labels mapping\n",
    "emotion_labels = {\n",
    "    'NE': 0,  # Neutral\n",
    "    'SA': 1,  # Sad\n",
    "    'SM': 2,  # Smile\n",
    "    'SO': 3,  # Surprise\n",
    "    'SU': 4,  # Surprise with Open mouth\n",
    "    'YN': 5   # Yawning\n",
    "}\n",
    "\n",
    "# Function to preprocess images for a specific orientation\n",
    "def preprocess_orientation_data(orientation):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for subject_id in range(1, 108):\n",
    "        if subject_id < 10:\n",
    "            file_prefix = f'SUB{subject_id}'\n",
    "            expression_start = 4\n",
    "            expression_end = 6\n",
    "            orientation_index = 6\n",
    "        elif subject_id < 100:\n",
    "            file_prefix = f'SUB{subject_id:02}'\n",
    "            expression_start = 5\n",
    "            expression_end = 7\n",
    "            orientation_index = 7\n",
    "        else:\n",
    "            file_prefix = f'SUB{subject_id:03}'\n",
    "            expression_start = 6\n",
    "            expression_end = 8\n",
    "            orientation_index = 8\n",
    "\n",
    "        folder_name = f'SUB{subject_id}'\n",
    "        folder_path = os.path.join(base_path, folder_name)\n",
    "        if os.path.exists(folder_path):\n",
    "            for file_name in os.listdir(folder_path):\n",
    "                if file_name.startswith(file_prefix):\n",
    "                    img_orientation = file_name[orientation_index]\n",
    "                    if img_orientation == orientation:\n",
    "                        expression = file_name[expression_start:expression_end]\n",
    "                        file_path = os.path.join(folder_path, file_name)\n",
    "                        image = imread(file_path)\n",
    "                        image_resized = resize(image, target_size, anti_aliasing=True)\n",
    "                        data.append(image_resized)\n",
    "                        labels.append(emotion_labels[expression])\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Preprocess data for each orientation and save them in dictionaries\n",
    "orientations = {'F': 'Front', 'U': 'Up', 'D': 'Down'}\n",
    "orientation_data = {}\n",
    "\n",
    "for ori_code, ori_name in orientations.items():\n",
    "    print(f\"Processing data for orientation: {ori_name}\")\n",
    "    data, labels = preprocess_orientation_data(ori_code)\n",
    "    orientation_data[ori_name] = (data, labels)\n",
    "\n",
    "print(\"Preprocessing complete for all orientations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75255e21-e73e-4b77-8eaa-4d8da1504527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for orientation: Front\n",
      "Epoch 1/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 594ms/step - accuracy: 0.1947 - loss: 18.9676\n",
      "Epoch 2/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 589ms/step - accuracy: 0.3066 - loss: 2.6492\n",
      "Epoch 3/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 587ms/step - accuracy: 0.5126 - loss: 1.6326\n",
      "Epoch 4/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 591ms/step - accuracy: 0.4416 - loss: 1.9824\n",
      "Epoch 5/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 591ms/step - accuracy: 0.7147 - loss: 0.7236\n",
      "Epoch 6/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 600ms/step - accuracy: 0.6174 - loss: 1.0032\n",
      "Epoch 7/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 591ms/step - accuracy: 0.8007 - loss: 0.6166\n",
      "Epoch 8/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 590ms/step - accuracy: 0.8463 - loss: 0.4243\n",
      "Epoch 9/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 593ms/step - accuracy: 0.8501 - loss: 0.4686\n",
      "Epoch 10/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 596ms/step - accuracy: 0.8260 - loss: 0.4422\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 479ms/step - accuracy: 0.4018 - loss: 2.0393\n",
      "Test accuracy for Front: 38.76%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step \n",
      "\n",
      "Classification report for Front:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NE       0.23      0.24      0.23        21\n",
      "          SA       0.38      0.14      0.21        21\n",
      "          SM       0.24      0.18      0.21        22\n",
      "          SO       0.75      0.55      0.63        22\n",
      "          SU       0.20      0.41      0.27        22\n",
      "          YN       0.81      0.81      0.81        21\n",
      "\n",
      "    accuracy                           0.39       129\n",
      "   macro avg       0.43      0.39      0.39       129\n",
      "weighted avg       0.43      0.39      0.39       129\n",
      "\n",
      "\n",
      "Training model for orientation: Up\n",
      "Epoch 1/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 611ms/step - accuracy: 0.1790 - loss: 17.5683\n",
      "Epoch 2/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 611ms/step - accuracy: 0.4358 - loss: 3.7716\n",
      "Epoch 3/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 621ms/step - accuracy: 0.5699 - loss: 1.6123\n",
      "Epoch 4/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 607ms/step - accuracy: 0.6414 - loss: 0.9911\n",
      "Epoch 5/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 608ms/step - accuracy: 0.8338 - loss: 0.4612\n",
      "Epoch 6/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 616ms/step - accuracy: 0.9244 - loss: 0.2574\n",
      "Epoch 7/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 612ms/step - accuracy: 0.9667 - loss: 0.1645\n",
      "Epoch 8/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 605ms/step - accuracy: 0.7498 - loss: 0.7049\n",
      "Epoch 9/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 615ms/step - accuracy: 0.7361 - loss: 0.9405\n",
      "Epoch 10/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 596ms/step - accuracy: 0.8083 - loss: 0.7536\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 478ms/step - accuracy: 0.4901 - loss: 2.5534\n",
      "Test accuracy for Up: 44.96%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step \n",
      "\n",
      "Classification report for Up:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NE       0.26      0.52      0.35        21\n",
      "          SA       0.25      0.10      0.14        21\n",
      "          SM       0.40      0.45      0.43        22\n",
      "          SO       0.64      0.73      0.68        22\n",
      "          SU       0.18      0.09      0.12        22\n",
      "          YN       0.94      0.81      0.87        21\n",
      "\n",
      "    accuracy                           0.45       129\n",
      "   macro avg       0.45      0.45      0.43       129\n",
      "weighted avg       0.45      0.45      0.43       129\n",
      "\n",
      "\n",
      "Training model for orientation: Down\n",
      "Epoch 1/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 581ms/step - accuracy: 0.1511 - loss: 19.6504\n",
      "Epoch 2/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 568ms/step - accuracy: 0.3205 - loss: 2.3926\n",
      "Epoch 3/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 572ms/step - accuracy: 0.5191 - loss: 1.2948\n",
      "Epoch 4/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 573ms/step - accuracy: 0.7070 - loss: 0.7957\n",
      "Epoch 5/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 586ms/step - accuracy: 0.8204 - loss: 0.5787\n",
      "Epoch 6/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 597ms/step - accuracy: 0.7774 - loss: 0.6712\n",
      "Epoch 7/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 604ms/step - accuracy: 0.8706 - loss: 0.4504\n",
      "Epoch 8/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 601ms/step - accuracy: 0.8846 - loss: 0.3692\n",
      "Epoch 9/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 593ms/step - accuracy: 0.9502 - loss: 0.2622\n",
      "Epoch 10/10\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 600ms/step - accuracy: 0.9658 - loss: 0.2373\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 484ms/step - accuracy: 0.3082 - loss: 2.0011\n",
      "Test accuracy for Down: 32.56%\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F1A6F989A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 585ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001F1A6F989A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step \n",
      "\n",
      "Classification report for Down:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NE       0.21      0.19      0.20        21\n",
      "          SA       0.00      0.00      0.00        21\n",
      "          SM       0.26      0.23      0.24        22\n",
      "          SO       0.45      0.23      0.30        22\n",
      "          SU       0.22      0.50      0.30        22\n",
      "          YN       0.61      0.81      0.69        21\n",
      "\n",
      "    accuracy                           0.33       129\n",
      "   macro avg       0.29      0.33      0.29       129\n",
      "weighted avg       0.29      0.33      0.29       129\n",
      "\n",
      "Training and evaluation complete for all orientations.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Train and evaluate model for each orientation\n",
    "results = {}\n",
    "\n",
    "for ori_name, (data, labels) in orientation_data.items():\n",
    "    print(f\"\\nTraining model for orientation: {ori_name}\")\n",
    "    \n",
    "    # Reshape data and convert labels to one-hot encoding\n",
    "    data = data.reshape(-1, 224, 224, 3)\n",
    "    labels_one_hot = to_categorical(labels, num_classes=len(emotion_labels))\n",
    "    \n",
    "    # Split into 80% training and 20% testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels_one_hot, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "    # Define the InceptionV3 model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False  # Freeze base model layers\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(len(emotion_labels), activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=1)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"Test accuracy for {ori_name}: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Generate a classification report\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    report = classification_report(y_test_classes, y_pred_classes, target_names=emotion_labels.keys())\n",
    "    \n",
    "    # Store results for each orientation\n",
    "    results[ori_name] = {\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'classification_report': report\n",
    "    }\n",
    "\n",
    "    print(f\"\\nClassification report for {ori_name}:\\n{report}\")\n",
    "\n",
    "print(\"Training and evaluation complete for all orientations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "279b9ae2-d621-4a30-a1cb-3a7ba980133b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for orientation: Front\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 1s/step - accuracy: 0.1504 - loss: 1.8171 - val_accuracy: 0.1628 - val_loss: 1.8021\n",
      "Epoch 2/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 919ms/step - accuracy: 0.1716 - loss: 1.7964 - val_accuracy: 0.1628 - val_loss: 1.8011\n",
      "Epoch 3/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 892ms/step - accuracy: 0.1491 - loss: 1.8015 - val_accuracy: 0.1628 - val_loss: 1.7997\n",
      "Epoch 4/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 939ms/step - accuracy: 0.1759 - loss: 1.7949 - val_accuracy: 0.1473 - val_loss: 1.7982\n",
      "Epoch 5/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 929ms/step - accuracy: 0.1722 - loss: 1.7987 - val_accuracy: 0.1628 - val_loss: 1.8213\n",
      "Epoch 6/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 899ms/step - accuracy: 0.1630 - loss: 1.8129 - val_accuracy: 0.1628 - val_loss: 1.8061\n",
      "Epoch 7/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 889ms/step - accuracy: 0.1488 - loss: 1.8030 - val_accuracy: 0.1705 - val_loss: 1.7976\n",
      "Epoch 8/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 909ms/step - accuracy: 0.1569 - loss: 1.7994 - val_accuracy: 0.1783 - val_loss: 1.7976\n",
      "Epoch 9/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 920ms/step - accuracy: 0.1705 - loss: 1.7965 - val_accuracy: 0.1318 - val_loss: 1.7955\n",
      "Epoch 10/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 915ms/step - accuracy: 0.1685 - loss: 1.7966 - val_accuracy: 0.1628 - val_loss: 1.8127\n",
      "Epoch 11/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 887ms/step - accuracy: 0.1691 - loss: 1.8062 - val_accuracy: 0.1318 - val_loss: 1.8028\n",
      "Epoch 12/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 926ms/step - accuracy: 0.1545 - loss: 1.8032 - val_accuracy: 0.1628 - val_loss: 1.8025\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 455ms/step - accuracy: 0.1459 - loss: 1.7919\n",
      "Test accuracy for Front: 13.18%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step \n",
      "\n",
      "Classification report for Front:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NE       0.00      0.00      0.00        21\n",
      "          SA       0.00      0.00      0.00        21\n",
      "          SM       0.00      0.00      0.00        22\n",
      "          SO       0.27      0.64      0.38        22\n",
      "          SU       0.00      0.00      0.00        22\n",
      "          YN       0.04      0.14      0.06        21\n",
      "\n",
      "    accuracy                           0.13       129\n",
      "   macro avg       0.05      0.13      0.07       129\n",
      "weighted avg       0.05      0.13      0.07       129\n",
      "\n",
      "\n",
      "Training model for orientation: Up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 1s/step - accuracy: 0.1704 - loss: 1.8095 - val_accuracy: 0.1705 - val_loss: 1.7979\n",
      "Epoch 2/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 1s/step - accuracy: 0.1321 - loss: 1.8095 - val_accuracy: 0.1628 - val_loss: 1.7970\n",
      "Epoch 3/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 976ms/step - accuracy: 0.1985 - loss: 1.7902 - val_accuracy: 0.1705 - val_loss: 1.7914\n",
      "Epoch 4/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 969ms/step - accuracy: 0.1208 - loss: 1.7991 - val_accuracy: 0.1628 - val_loss: 1.7921\n",
      "Epoch 5/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 1s/step - accuracy: 0.1381 - loss: 1.7999 - val_accuracy: 0.1705 - val_loss: 1.7913\n",
      "Epoch 6/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 936ms/step - accuracy: 0.1584 - loss: 1.7968 - val_accuracy: 0.1705 - val_loss: 1.7961\n",
      "Epoch 7/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 950ms/step - accuracy: 0.1589 - loss: 1.8015 - val_accuracy: 0.2016 - val_loss: 1.7909\n",
      "Epoch 8/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 938ms/step - accuracy: 0.1633 - loss: 1.7937 - val_accuracy: 0.1705 - val_loss: 1.7912\n",
      "Epoch 9/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 932ms/step - accuracy: 0.1767 - loss: 1.7930 - val_accuracy: 0.1860 - val_loss: 1.7912\n",
      "Epoch 10/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 903ms/step - accuracy: 0.1662 - loss: 1.7967 - val_accuracy: 0.1628 - val_loss: 1.7942\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 535ms/step - accuracy: 0.2043 - loss: 1.7899\n",
      "Test accuracy for Up: 20.16%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step \n",
      "\n",
      "Classification report for Up:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NE       0.00      0.00      0.00        21\n",
      "          SA       0.00      0.00      0.00        21\n",
      "          SM       0.00      0.00      0.00        22\n",
      "          SO       0.20      1.00      0.33        22\n",
      "          SU       0.24      0.18      0.21        22\n",
      "          YN       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.20       129\n",
      "   macro avg       0.07      0.20      0.09       129\n",
      "weighted avg       0.07      0.20      0.09       129\n",
      "\n",
      "\n",
      "Training model for orientation: Down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.1912 - loss: 1.8049 - val_accuracy: 0.1705 - val_loss: 1.7996\n",
      "Epoch 2/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 935ms/step - accuracy: 0.1547 - loss: 1.8008 - val_accuracy: 0.1705 - val_loss: 1.7968\n",
      "Epoch 3/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 933ms/step - accuracy: 0.1570 - loss: 1.7979 - val_accuracy: 0.1628 - val_loss: 1.7989\n",
      "Epoch 4/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 917ms/step - accuracy: 0.1681 - loss: 1.7981 - val_accuracy: 0.1628 - val_loss: 1.8026\n",
      "Epoch 5/20\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 936ms/step - accuracy: 0.1712 - loss: 1.7935 - val_accuracy: 0.1705 - val_loss: 1.7983\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 510ms/step - accuracy: 0.1597 - loss: 1.7987\n",
      "Test accuracy for Down: 17.05%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2s/step \n",
      "\n",
      "Classification report for Down:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NE       0.00      0.00      0.00        21\n",
      "          SA       0.00      0.00      0.00        21\n",
      "          SM       0.00      0.00      0.00        22\n",
      "          SO       0.00      0.00      0.00        22\n",
      "          SU       0.17      1.00      0.29        22\n",
      "          YN       0.00      0.00      0.00        21\n",
      "\n",
      "    accuracy                           0.17       129\n",
      "   macro avg       0.03      0.17      0.05       129\n",
      "weighted avg       0.03      0.17      0.05       129\n",
      "\n",
      "Training and evaluation complete for all orientations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Define emotion labels (ensure these match your dataset's labels)\n",
    "emotion_labels = ['NE', 'SA', 'SM', 'SO', 'SU', 'YN']\n",
    "\n",
    "# Train and evaluate model for each orientation\n",
    "results = {}\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values\n",
    "    rotation_range=30,  # Random rotations\n",
    "    width_shift_range=0.2,  # Horizontal shifts\n",
    "    height_shift_range=0.2,  # Vertical shifts\n",
    "    shear_range=0.2,  # Shearing transformations\n",
    "    zoom_range=0.2,  # Zooming in and out\n",
    "    horizontal_flip=True,  # Random horizontal flips\n",
    "    fill_mode='nearest'  # Fill missing pixels after transformations\n",
    ")\n",
    "\n",
    "for ori_name, (data, labels) in orientation_data.items():\n",
    "    print(f\"\\nTraining model for orientation: {ori_name}\")\n",
    "    \n",
    "    # Reshape data and convert labels to one-hot encoding\n",
    "    data = data.reshape(-1, 224, 224, 3)\n",
    "    data = data.astype('float32') / 255.0  # Normalize pixel values\n",
    "    labels_one_hot = to_categorical(labels, num_classes=len(emotion_labels))\n",
    "    \n",
    "    # Split into 80% training and 20% testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels_one_hot, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "    # Apply data augmentation to training data\n",
    "    train_datagen = datagen.flow(X_train, y_train, batch_size=32)\n",
    "\n",
    "    # Define the InceptionV3 model\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    base_model.trainable = False  # Freeze the base model initially\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)  # Use global average pooling instead of flatten for better performance\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(len(emotion_labels), activation='softmax')(x)\n",
    "    \n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Implement early stopping\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    # Train the model with early stopping\n",
    "    model.fit(train_datagen, epochs=20, validation_data=(X_test, y_test), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"Test accuracy for {ori_name}: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Generate a classification report\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    report = classification_report(y_test_classes, y_pred_classes, target_names=emotion_labels)\n",
    "    \n",
    "    # Store results for each orientation\n",
    "    results[ori_name] = {\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'classification_report': report\n",
    "    }\n",
    "\n",
    "    print(f\"\\nClassification report for {ori_name}:\\n{report}\")\n",
    "\n",
    "print(\"Training and evaluation complete for all orientations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7a007a6-a0e8-46cf-8d07-ce22d853892c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for orientation: Front\n",
      "Training images for Front: 513, Testing images: 129\n",
      "Epoch 1/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 288ms/step - accuracy: 0.2584 - loss: 6.3857\n",
      "Epoch 2/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.4111 - loss: 1.3836\n",
      "Epoch 3/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 290ms/step - accuracy: 0.5424 - loss: 1.0821\n",
      "Epoch 4/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 290ms/step - accuracy: 0.5799 - loss: 0.9794\n",
      "Epoch 5/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 309ms/step - accuracy: 0.5786 - loss: 1.0300\n",
      "Epoch 6/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 323ms/step - accuracy: 0.5718 - loss: 1.0541\n",
      "Epoch 7/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - accuracy: 0.5925 - loss: 1.0634\n",
      "Epoch 8/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 322ms/step - accuracy: 0.6863 - loss: 0.8244\n",
      "Epoch 9/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 345ms/step - accuracy: 0.7422 - loss: 0.8560\n",
      "Epoch 10/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 328ms/step - accuracy: 0.7489 - loss: 0.7360\n",
      "Epoch 11/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 313ms/step - accuracy: 0.6223 - loss: 0.9845\n",
      "Epoch 12/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 310ms/step - accuracy: 0.5926 - loss: 1.0519\n",
      "Epoch 13/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 319ms/step - accuracy: 0.6589 - loss: 0.8365\n",
      "Epoch 14/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 326ms/step - accuracy: 0.7160 - loss: 0.7519\n",
      "Epoch 15/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 322ms/step - accuracy: 0.7484 - loss: 0.9499\n",
      "Epoch 16/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 326ms/step - accuracy: 0.7638 - loss: 0.7009\n",
      "Epoch 17/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 337ms/step - accuracy: 0.8304 - loss: 0.4986\n",
      "Epoch 18/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - accuracy: 0.7528 - loss: 0.8680\n",
      "Epoch 19/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 309ms/step - accuracy: 0.7996 - loss: 0.5633\n",
      "Epoch 20/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 303ms/step - accuracy: 0.8100 - loss: 0.6002\n",
      "Epoch 21/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 321ms/step - accuracy: 0.8721 - loss: 0.4199\n",
      "Epoch 22/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.8073 - loss: 0.6422\n",
      "Epoch 23/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 292ms/step - accuracy: 0.7717 - loss: 0.7614\n",
      "Epoch 24/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 300ms/step - accuracy: 0.7993 - loss: 0.6867\n",
      "Epoch 25/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 0.7781 - loss: 0.6283\n",
      "Epoch 26/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 285ms/step - accuracy: 0.8298 - loss: 0.5312\n",
      "Epoch 27/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 297ms/step - accuracy: 0.8737 - loss: 0.4812\n",
      "Epoch 28/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 289ms/step - accuracy: 0.7301 - loss: 0.8003\n",
      "Epoch 29/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 297ms/step - accuracy: 0.7772 - loss: 0.6980\n",
      "Epoch 30/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 296ms/step - accuracy: 0.7847 - loss: 0.7532\n",
      "Epoch 31/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 299ms/step - accuracy: 0.7697 - loss: 0.6226\n",
      "Epoch 32/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.7365 - loss: 1.0630\n",
      "Epoch 33/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 334ms/step - accuracy: 0.7794 - loss: 0.6996\n",
      "Epoch 34/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 275ms/step - accuracy: 0.8297 - loss: 0.5762\n",
      "Epoch 35/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 275ms/step - accuracy: 0.7248 - loss: 0.6997\n",
      "Epoch 36/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 277ms/step - accuracy: 0.7737 - loss: 0.5928\n",
      "Epoch 37/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 272ms/step - accuracy: 0.7821 - loss: 0.5028\n",
      "Epoch 38/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 274ms/step - accuracy: 0.8303 - loss: 0.3929\n",
      "Epoch 39/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 276ms/step - accuracy: 0.8472 - loss: 0.3795\n",
      "Epoch 40/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 279ms/step - accuracy: 0.8994 - loss: 0.3254\n",
      "Epoch 41/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 274ms/step - accuracy: 0.8973 - loss: 0.3158\n",
      "Epoch 42/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 272ms/step - accuracy: 0.8053 - loss: 0.6053\n",
      "Epoch 43/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 279ms/step - accuracy: 0.8336 - loss: 0.4641\n",
      "Epoch 44/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 274ms/step - accuracy: 0.8716 - loss: 0.4848\n",
      "Epoch 45/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 272ms/step - accuracy: 0.9035 - loss: 0.3552\n",
      "Epoch 46/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 273ms/step - accuracy: 0.9053 - loss: 0.3319\n",
      "Epoch 47/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 273ms/step - accuracy: 0.9351 - loss: 0.1889\n",
      "Epoch 48/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 275ms/step - accuracy: 0.9517 - loss: 0.4007\n",
      "Epoch 49/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 273ms/step - accuracy: 0.8665 - loss: 0.4268\n",
      "Epoch 50/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 272ms/step - accuracy: 0.7502 - loss: 0.6858\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 134ms/step - accuracy: 0.1897 - loss: 4.4538\n",
      "Test accuracy for Front: 17.05%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 541ms/step\n",
      "\n",
      "Classification report for Front:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NE       0.00      0.00      0.00        21\n",
      "          SA       0.00      0.00      0.00        21\n",
      "          SM       0.00      0.00      0.00        22\n",
      "          SO       0.50      0.05      0.08        22\n",
      "          SU       0.00      0.00      0.00        22\n",
      "          YN       0.17      1.00      0.28        21\n",
      "\n",
      "    accuracy                           0.17       129\n",
      "   macro avg       0.11      0.17      0.06       129\n",
      "weighted avg       0.11      0.17      0.06       129\n",
      "\n",
      "\n",
      "Training model for orientation: Up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images for Up: 513, Testing images: 129\n",
      "Epoch 1/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 291ms/step - accuracy: 0.2357 - loss: 4.8104\n",
      "Epoch 2/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 285ms/step - accuracy: 0.3601 - loss: 1.4802\n",
      "Epoch 3/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 290ms/step - accuracy: 0.4232 - loss: 1.3610\n",
      "Epoch 4/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.4830 - loss: 1.2793\n",
      "Epoch 5/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - accuracy: 0.5530 - loss: 1.0395\n",
      "Epoch 6/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.6263 - loss: 0.9210\n",
      "Epoch 7/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.6956 - loss: 0.7228\n",
      "Epoch 8/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.6445 - loss: 0.8954\n",
      "Epoch 9/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.7171 - loss: 0.7279\n",
      "Epoch 10/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.7485 - loss: 0.6640\n",
      "Epoch 11/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.7204 - loss: 0.7679\n",
      "Epoch 12/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 295ms/step - accuracy: 0.6039 - loss: 1.2083\n",
      "Epoch 13/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 302ms/step - accuracy: 0.6907 - loss: 0.7286\n",
      "Epoch 14/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 293ms/step - accuracy: 0.7016 - loss: 0.8894\n",
      "Epoch 15/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 297ms/step - accuracy: 0.6850 - loss: 0.8469\n",
      "Epoch 16/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 306ms/step - accuracy: 0.7248 - loss: 0.6800\n",
      "Epoch 17/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 297ms/step - accuracy: 0.7276 - loss: 0.6672\n",
      "Epoch 18/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 303ms/step - accuracy: 0.7499 - loss: 0.7598\n",
      "Epoch 19/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.6812 - loss: 0.8462\n",
      "Epoch 20/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.7234 - loss: 0.5990\n",
      "Epoch 21/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.7500 - loss: 0.6311\n",
      "Epoch 22/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 283ms/step - accuracy: 0.7959 - loss: 0.4519\n",
      "Epoch 23/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.7990 - loss: 0.5228\n",
      "Epoch 24/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 282ms/step - accuracy: 0.7568 - loss: 0.5671\n",
      "Epoch 25/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.7780 - loss: 0.7062\n",
      "Epoch 26/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 0.7842 - loss: 0.5757\n",
      "Epoch 27/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 296ms/step - accuracy: 0.7954 - loss: 0.4712\n",
      "Epoch 28/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 292ms/step - accuracy: 0.8126 - loss: 0.4572\n",
      "Epoch 29/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 295ms/step - accuracy: 0.8618 - loss: 0.3230\n",
      "Epoch 30/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 301ms/step - accuracy: 0.7660 - loss: 0.4733\n",
      "Epoch 31/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 0.7577 - loss: 0.5062\n",
      "Epoch 32/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 290ms/step - accuracy: 0.7933 - loss: 0.4187\n",
      "Epoch 33/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 295ms/step - accuracy: 0.8409 - loss: 0.3543\n",
      "Epoch 34/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 0.8191 - loss: 0.4895\n",
      "Epoch 35/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 0.8170 - loss: 0.4731\n",
      "Epoch 36/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 0.8327 - loss: 0.3830\n",
      "Epoch 37/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 290ms/step - accuracy: 0.8771 - loss: 0.3198\n",
      "Epoch 38/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 298ms/step - accuracy: 0.8609 - loss: 0.3721\n",
      "Epoch 39/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 297ms/step - accuracy: 0.8698 - loss: 0.3925\n",
      "Epoch 40/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 295ms/step - accuracy: 0.8240 - loss: 0.6541\n",
      "Epoch 41/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 293ms/step - accuracy: 0.8717 - loss: 0.4200\n",
      "Epoch 42/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 292ms/step - accuracy: 0.8268 - loss: 0.4400\n",
      "Epoch 43/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 292ms/step - accuracy: 0.8349 - loss: 0.4990\n",
      "Epoch 44/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 0.8797 - loss: 0.4429\n",
      "Epoch 45/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 291ms/step - accuracy: 0.8576 - loss: 0.3526\n",
      "Epoch 46/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 301ms/step - accuracy: 0.8807 - loss: 0.4409\n",
      "Epoch 47/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 296ms/step - accuracy: 0.9317 - loss: 0.2260\n",
      "Epoch 48/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 307ms/step - accuracy: 0.9029 - loss: 0.4026\n",
      "Epoch 49/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - accuracy: 0.8271 - loss: 0.5821\n",
      "Epoch 50/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.8724 - loss: 0.3823\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 149ms/step - accuracy: 0.5330 - loss: 2.4607\n",
      "Test accuracy for Up: 50.39%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 477ms/step\n",
      "\n",
      "Classification report for Up:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NE       0.27      0.76      0.40        21\n",
      "          SA       0.36      0.24      0.29        21\n",
      "          SM       0.55      0.27      0.36        22\n",
      "          SO       0.86      0.86      0.86        22\n",
      "          SU       0.00      0.00      0.00        22\n",
      "          YN       1.00      0.90      0.95        21\n",
      "\n",
      "    accuracy                           0.50       129\n",
      "   macro avg       0.51      0.51      0.48       129\n",
      "weighted avg       0.51      0.50      0.48       129\n",
      "\n",
      "\n",
      "Training model for orientation: Down\n",
      "Training images for Down: 513, Testing images: 129\n",
      "Epoch 1/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 299ms/step - accuracy: 0.2407 - loss: 5.4620\n",
      "Epoch 2/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 299ms/step - accuracy: 0.3827 - loss: 1.4265\n",
      "Epoch 3/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 297ms/step - accuracy: 0.4269 - loss: 1.3040\n",
      "Epoch 4/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 306ms/step - accuracy: 0.4749 - loss: 1.2699\n",
      "Epoch 5/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 315ms/step - accuracy: 0.5364 - loss: 1.0115\n",
      "Epoch 6/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 319ms/step - accuracy: 0.6032 - loss: 0.9971\n",
      "Epoch 7/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 304ms/step - accuracy: 0.6558 - loss: 0.9248\n",
      "Epoch 8/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 308ms/step - accuracy: 0.7320 - loss: 0.7064\n",
      "Epoch 9/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 296ms/step - accuracy: 0.6929 - loss: 0.7861\n",
      "Epoch 10/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 294ms/step - accuracy: 0.6696 - loss: 0.9848\n",
      "Epoch 11/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 296ms/step - accuracy: 0.6469 - loss: 0.8872\n",
      "Epoch 12/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 294ms/step - accuracy: 0.7022 - loss: 0.8304\n",
      "Epoch 13/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 299ms/step - accuracy: 0.6303 - loss: 0.9345\n",
      "Epoch 14/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 318ms/step - accuracy: 0.5456 - loss: 1.3525\n",
      "Epoch 15/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 289ms/step - accuracy: 0.5792 - loss: 1.0709\n",
      "Epoch 16/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 298ms/step - accuracy: 0.5943 - loss: 1.0488\n",
      "Epoch 17/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 290ms/step - accuracy: 0.6339 - loss: 0.8403\n",
      "Epoch 18/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 286ms/step - accuracy: 0.7319 - loss: 0.6243\n",
      "Epoch 19/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 297ms/step - accuracy: 0.7164 - loss: 0.7570\n",
      "Epoch 20/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 293ms/step - accuracy: 0.7440 - loss: 0.6692\n",
      "Epoch 21/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 319ms/step - accuracy: 0.7400 - loss: 0.6704\n",
      "Epoch 22/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 313ms/step - accuracy: 0.7684 - loss: 0.5929\n",
      "Epoch 23/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 306ms/step - accuracy: 0.7744 - loss: 0.6940\n",
      "Epoch 24/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 288ms/step - accuracy: 0.7787 - loss: 0.5789\n",
      "Epoch 25/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 287ms/step - accuracy: 0.8303 - loss: 0.5085\n",
      "Epoch 26/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 294ms/step - accuracy: 0.8282 - loss: 0.4687\n",
      "Epoch 27/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 289ms/step - accuracy: 0.8516 - loss: 0.4200\n",
      "Epoch 28/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 310ms/step - accuracy: 0.8565 - loss: 0.4266\n",
      "Epoch 29/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 295ms/step - accuracy: 0.6270 - loss: 0.9885\n",
      "Epoch 30/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 304ms/step - accuracy: 0.6603 - loss: 0.8599\n",
      "Epoch 31/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 308ms/step - accuracy: 0.6609 - loss: 0.8113\n",
      "Epoch 32/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 301ms/step - accuracy: 0.7591 - loss: 0.5894\n",
      "Epoch 33/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - accuracy: 0.7762 - loss: 0.6081\n",
      "Epoch 34/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 307ms/step - accuracy: 0.7937 - loss: 0.4804\n",
      "Epoch 35/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 308ms/step - accuracy: 0.8639 - loss: 0.3775\n",
      "Epoch 36/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 308ms/step - accuracy: 0.8588 - loss: 0.4251\n",
      "Epoch 37/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 308ms/step - accuracy: 0.8277 - loss: 0.5112\n",
      "Epoch 38/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 300ms/step - accuracy: 0.8904 - loss: 0.3950\n",
      "Epoch 39/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 308ms/step - accuracy: 0.8584 - loss: 0.4865\n",
      "Epoch 40/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 303ms/step - accuracy: 0.8329 - loss: 0.4423\n",
      "Epoch 41/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 305ms/step - accuracy: 0.8586 - loss: 0.4479\n",
      "Epoch 42/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 302ms/step - accuracy: 0.8272 - loss: 0.5534\n",
      "Epoch 43/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 308ms/step - accuracy: 0.8276 - loss: 0.5917\n",
      "Epoch 44/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 296ms/step - accuracy: 0.8659 - loss: 0.4150\n",
      "Epoch 45/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 310ms/step - accuracy: 0.8318 - loss: 0.4683\n",
      "Epoch 46/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 304ms/step - accuracy: 0.8018 - loss: 0.4931\n",
      "Epoch 47/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 290ms/step - accuracy: 0.8675 - loss: 0.4254\n",
      "Epoch 48/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 271ms/step - accuracy: 0.8122 - loss: 0.4711\n",
      "Epoch 49/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 282ms/step - accuracy: 0.8868 - loss: 0.3121\n",
      "Epoch 50/50\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 275ms/step - accuracy: 0.8242 - loss: 0.4626\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 161ms/step - accuracy: 0.4524 - loss: 2.1101\n",
      "Test accuracy for Down: 44.19%\n",
      "WARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002306E389BC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m4/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━\u001b[0m \u001b[1m0s\u001b[0m 172ms/stepWARNING:tensorflow:5 out of the last 11 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000002306E389BC0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 469ms/step\n",
      "\n",
      "Classification report for Down:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NE       0.28      0.76      0.41        21\n",
      "          SA       1.00      0.10      0.17        21\n",
      "          SM       0.00      0.00      0.00        22\n",
      "          SO       0.67      0.82      0.73        22\n",
      "          SU       0.32      0.45      0.38        22\n",
      "          YN       0.92      0.52      0.67        21\n",
      "\n",
      "    accuracy                           0.44       129\n",
      "   macro avg       0.53      0.44      0.39       129\n",
      "weighted avg       0.53      0.44      0.39       129\n",
      "\n",
      "Training and evaluation complete for all orientations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Assuming emotion_labels is a list of emotion labels\n",
    "emotion_labels = ['NE', 'SA', 'SM', 'SO', 'SU', 'YN']\n",
    "\n",
    "# Model selection: MobileNetV2\n",
    "model_choice = 'MobileNetV2'\n",
    "\n",
    "# Train and evaluate model for each orientation\n",
    "results = {}\n",
    "\n",
    "for ori_name, (data, labels) in orientation_data.items():\n",
    "    print(f\"\\nTraining model for orientation: {ori_name}\")\n",
    "    \n",
    "    # Reshape data and convert labels to one-hot encoding\n",
    "    data = data.reshape(-1, 224, 224, 3)\n",
    "    labels_one_hot = to_categorical(labels, num_classes=len(emotion_labels))\n",
    "    \n",
    "    # Split into 80% training and 20% testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, labels_one_hot, test_size=0.2, random_state=42, stratify=labels)\n",
    "    \n",
    "    # Print number of images in the training and testing sets\n",
    "    print(f\"Training images for {ori_name}: {X_train.shape[0]}, Testing images: {X_test.shape[0]}\")\n",
    "\n",
    "    # Choose base model: MobileNetV2\n",
    "    if model_choice == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Unfreeze some layers of the base model\n",
    "    base_model.trainable = True  # Unfreeze the entire base model\n",
    "    fine_tune_at = 100  # Fine-tune from a certain layer onwards (optional)\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False  # Freeze earlier layers\n",
    "\n",
    "    # Add custom layers on top\n",
    "    x = Flatten()(base_model.output)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)  # Add dropout layer for regularization\n",
    "    output = Dense(len(emotion_labels), activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    # Compile the model with a lower learning rate\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train, epochs=50, batch_size=32, verbose=1)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"Test accuracy for {ori_name}: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Generate a classification report\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    report = classification_report(y_test_classes, y_pred_classes, target_names=emotion_labels)\n",
    "    \n",
    "    # Store results for each orientation\n",
    "    results[ori_name] = {\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'classification_report': report\n",
    "    }\n",
    "\n",
    "    print(f\"\\nClassification report for {ori_name}:\\n{report}\")\n",
    "\n",
    "print(\"Training and evaluation complete for all orientations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ba3bc5c4-4949-4344-99f7-cdf9f6c63f03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for orientation: Front\n",
      "Training images for Front: 513, Testing images: 129\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 922ms/step - accuracy: 0.2462 - loss: 1.8891 - val_accuracy: 0.2248 - val_loss: 1.8246\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 722ms/step - accuracy: 0.4879 - loss: 1.2049 - val_accuracy: 0.3333 - val_loss: 2.1039\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 716ms/step - accuracy: 0.6048 - loss: 0.9901 - val_accuracy: 0.3411 - val_loss: 2.7557\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 764ms/step - accuracy: 0.6616 - loss: 0.8377 - val_accuracy: 0.3643 - val_loss: 2.3306\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 702ms/step - accuracy: 0.7036 - loss: 0.7862 - val_accuracy: 0.3488 - val_loss: 2.9956\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 770ms/step - accuracy: 0.7001 - loss: 0.8306 - val_accuracy: 0.3566 - val_loss: 3.3495\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 204ms/step - accuracy: 0.1999 - loss: 1.8239\n",
      "Test accuracy for Front: 22.48%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 741ms/step\n",
      "\n",
      "Classification report for Front:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NE       0.33      0.05      0.08        21\n",
      "          SA       0.00      0.00      0.00        21\n",
      "          SM       0.20      0.18      0.19        22\n",
      "          SO       0.25      0.05      0.08        22\n",
      "          SU       0.19      0.82      0.30        22\n",
      "          YN       1.00      0.24      0.38        21\n",
      "\n",
      "    accuracy                           0.22       129\n",
      "   macro avg       0.33      0.22      0.17       129\n",
      "weighted avg       0.33      0.22      0.17       129\n",
      "\n",
      "\n",
      "Training model for orientation: Up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training images for Up: 513, Testing images: 129\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 902ms/step - accuracy: 0.2420 - loss: 1.9542 - val_accuracy: 0.3101 - val_loss: 1.9546\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 718ms/step - accuracy: 0.4534 - loss: 1.2877 - val_accuracy: 0.3643 - val_loss: 2.0053\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 684ms/step - accuracy: 0.5919 - loss: 1.1052 - val_accuracy: 0.3953 - val_loss: 2.0765\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 763ms/step - accuracy: 0.5782 - loss: 1.0238 - val_accuracy: 0.4729 - val_loss: 1.4715\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 788ms/step - accuracy: 0.6365 - loss: 0.8956 - val_accuracy: 0.4884 - val_loss: 1.4141\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 758ms/step - accuracy: 0.6680 - loss: 0.8374 - val_accuracy: 0.4884 - val_loss: 1.4094\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 716ms/step - accuracy: 0.6436 - loss: 0.8544 - val_accuracy: 0.4961 - val_loss: 2.0122\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 710ms/step - accuracy: 0.6878 - loss: 0.7923 - val_accuracy: 0.4419 - val_loss: 3.1150\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 740ms/step - accuracy: 0.7649 - loss: 0.5758 - val_accuracy: 0.4341 - val_loss: 3.2742\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 688ms/step - accuracy: 0.6977 - loss: 0.7151 - val_accuracy: 0.4961 - val_loss: 1.8757\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 745ms/step - accuracy: 0.6699 - loss: 0.8805 - val_accuracy: 0.4806 - val_loss: 1.8989\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 239ms/step - accuracy: 0.5178 - loss: 1.3314\n",
      "Test accuracy for Up: 48.84%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 751ms/step\n",
      "\n",
      "Classification report for Up:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NE       0.31      0.86      0.46        21\n",
      "          SA       0.57      0.19      0.29        21\n",
      "          SM       1.00      0.18      0.31        22\n",
      "          SO       0.83      0.45      0.59        22\n",
      "          SU       0.28      0.36      0.31        22\n",
      "          YN       1.00      0.90      0.95        21\n",
      "\n",
      "    accuracy                           0.49       129\n",
      "   macro avg       0.67      0.49      0.48       129\n",
      "weighted avg       0.67      0.49      0.48       129\n",
      "\n",
      "\n",
      "Training model for orientation: Down\n",
      "Training images for Down: 513, Testing images: 129\n",
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 947ms/step - accuracy: 0.2755 - loss: 1.8374 - val_accuracy: 0.2326 - val_loss: 1.5942\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 810ms/step - accuracy: 0.4235 - loss: 1.3404 - val_accuracy: 0.3566 - val_loss: 1.5121\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 711ms/step - accuracy: 0.4470 - loss: 1.2264 - val_accuracy: 0.3721 - val_loss: 1.8135\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 749ms/step - accuracy: 0.5034 - loss: 1.1609 - val_accuracy: 0.3798 - val_loss: 1.6510\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 778ms/step - accuracy: 0.5644 - loss: 0.9778 - val_accuracy: 0.3488 - val_loss: 2.0077\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 720ms/step - accuracy: 0.6347 - loss: 0.8820 - val_accuracy: 0.3333 - val_loss: 2.3927\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 746ms/step - accuracy: 0.6828 - loss: 0.7799 - val_accuracy: 0.3023 - val_loss: 2.5817\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 275ms/step - accuracy: 0.3732 - loss: 1.5067\n",
      "Test accuracy for Down: 35.66%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 731ms/step\n",
      "\n",
      "Classification report for Down:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          NE       0.27      0.86      0.41        21\n",
      "          SA       1.00      0.10      0.17        21\n",
      "          SM       0.00      0.00      0.00        22\n",
      "          SO       1.00      0.05      0.09        22\n",
      "          SU       0.33      0.23      0.27        22\n",
      "          YN       0.45      0.95      0.62        21\n",
      "\n",
      "    accuracy                           0.36       129\n",
      "   macro avg       0.51      0.36      0.26       129\n",
      "weighted avg       0.51      0.36      0.26       129\n",
      "\n",
      "Training and evaluation complete for all orientations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Assuming emotion_labels is a list of emotion labels\n",
    "emotion_labels = ['NE', 'SA', 'SM', 'SO', 'SU', 'YN']\n",
    "\n",
    "# Model selection: MobileNetV2\n",
    "model_choice = 'MobileNetV2'\n",
    "\n",
    "# Train and evaluate model for each orientation\n",
    "results = {}\n",
    "\n",
    "for ori_name, (data, labels) in orientation_data.items():\n",
    "    print(f\"\\nTraining model for orientation: {ori_name}\")\n",
    "    \n",
    "    # Reshape data and convert labels to one-hot encoding\n",
    "    data = data.reshape(-1, 224, 224, 3)\n",
    "    labels_one_hot = to_categorical(labels, num_classes=len(emotion_labels))\n",
    "    \n",
    "    # Split into 80% training and 20% testing sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        data, labels_one_hot, test_size=0.2, random_state=42, stratify=labels)\n",
    "    \n",
    "    # Print number of images in the training and testing sets\n",
    "    print(f\"Training images for {ori_name}: {X_train.shape[0]}, Testing images: {X_test.shape[0]}\")\n",
    "\n",
    "    # Data Augmentation\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        zoom_range=0.2\n",
    "    )\n",
    "\n",
    "    # Choose base model: MobileNetV2\n",
    "    if model_choice == 'MobileNetV2':\n",
    "        base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Unfreeze some layers of the base model\n",
    "    base_model.trainable = True\n",
    "    fine_tune_at = 100\n",
    "    for layer in base_model.layers[:fine_tune_at]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Add custom layers on top\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)  # Dropout for regularization\n",
    "    output = Dense(len(emotion_labels), activation='softmax')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    # Compile the model with a lower learning rate\n",
    "    model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    # Callbacks\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "    model_checkpoint = ModelCheckpoint(f\"{ori_name}_best_model.keras\", save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "    # Train the model with data augmentation\n",
    "    model.fit(\n",
    "        datagen.flow(X_train, y_train, batch_size=32),\n",
    "        epochs=30,\n",
    "        validation_data=(X_test, y_test),\n",
    "        callbacks=[early_stopping, model_checkpoint],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Load the best model weights\n",
    "    model.load_weights(f\"{ori_name}_best_model.keras\")\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print(f\"Test accuracy for {ori_name}: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Generate a classification report\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "    y_test_classes = np.argmax(y_test, axis=1)\n",
    "    report = classification_report(y_test_classes, y_pred_classes, target_names=emotion_labels)\n",
    "    \n",
    "    # Store results for each orientation\n",
    "    results[ori_name] = {\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'classification_report': report\n",
    "    }\n",
    "\n",
    "    print(f\"\\nClassification report for {ori_name}:\\n{report}\")\n",
    "\n",
    "print(\"Training and evaluation complete for all orientations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b26fd999-b99c-4e88-9a1a-810a83303fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for orientation: Front\n",
      "\n",
      "Starting fold 1 for orientation Front\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 514ms/step - accuracy: 0.2531 - loss: 4.5456 - val_accuracy: 0.1938 - val_loss: 2.4427\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 390ms/step - accuracy: 0.4924 - loss: 1.2295 - val_accuracy: 0.3256 - val_loss: 2.8483\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 372ms/step - accuracy: 0.5611 - loss: 1.0902 - val_accuracy: 0.4109 - val_loss: 2.5005\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 385ms/step - accuracy: 0.6121 - loss: 0.9052 - val_accuracy: 0.4419 - val_loss: 3.1643\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 373ms/step - accuracy: 0.6950 - loss: 0.8846 - val_accuracy: 0.2713 - val_loss: 7.9932\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 396ms/step - accuracy: 0.6466 - loss: 1.0663 - val_accuracy: 0.2791 - val_loss: 4.7122\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 374ms/step - accuracy: 0.6686 - loss: 0.7911 - val_accuracy: 0.3798 - val_loss: 3.7054\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 390ms/step - accuracy: 0.7161 - loss: 0.7044 - val_accuracy: 0.3721 - val_loss: 3.9302\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 385ms/step - accuracy: 0.6878 - loss: 0.7883 - val_accuracy: 0.3101 - val_loss: 7.0753\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 383ms/step - accuracy: 0.6706 - loss: 0.8014 - val_accuracy: 0.3798 - val_loss: 4.7480\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 370ms/step - accuracy: 0.7565 - loss: 0.6560 - val_accuracy: 0.4109 - val_loss: 6.6543\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 172ms/step - accuracy: 0.2065 - loss: 2.4280\n",
      "Validation accuracy for fold 1 of Front: 19.38%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 737ms/step\n",
      "\n",
      "Starting fold 2 for orientation Front\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 449ms/step - accuracy: 0.2447 - loss: 4.7032 - val_accuracy: 0.1783 - val_loss: 2.3945\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 362ms/step - accuracy: 0.4155 - loss: 1.4271 - val_accuracy: 0.2636 - val_loss: 1.8431\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 382ms/step - accuracy: 0.5622 - loss: 1.1063 - val_accuracy: 0.3411 - val_loss: 2.0847\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 372ms/step - accuracy: 0.5701 - loss: 1.0606 - val_accuracy: 0.2713 - val_loss: 1.9781\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 373ms/step - accuracy: 0.6283 - loss: 0.9662 - val_accuracy: 0.2946 - val_loss: 2.4887\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 372ms/step - accuracy: 0.7037 - loss: 0.7918 - val_accuracy: 0.1783 - val_loss: 3.2021\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 356ms/step - accuracy: 0.6957 - loss: 0.7925 - val_accuracy: 0.2481 - val_loss: 4.1434\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 358ms/step - accuracy: 0.6464 - loss: 0.9565 - val_accuracy: 0.3488 - val_loss: 2.0591\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 367ms/step - accuracy: 0.6694 - loss: 0.8936 - val_accuracy: 0.3178 - val_loss: 3.3309\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 314ms/step - accuracy: 0.7266 - loss: 0.7532 - val_accuracy: 0.3566 - val_loss: 4.2662\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 337ms/step - accuracy: 0.7269 - loss: 0.8253 - val_accuracy: 0.3178 - val_loss: 6.0400\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 340ms/step - accuracy: 0.8212 - loss: 0.4842 - val_accuracy: 0.3798 - val_loss: 4.2033\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 150ms/step - accuracy: 0.2979 - loss: 1.8551\n",
      "Validation accuracy for fold 2 of Front: 26.36%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 543ms/step\n",
      "\n",
      "Starting fold 3 for orientation Front\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 556ms/step - accuracy: 0.2493 - loss: 3.5362 - val_accuracy: 0.2031 - val_loss: 5.1829\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 360ms/step - accuracy: 0.4190 - loss: 1.4180 - val_accuracy: 0.1172 - val_loss: 5.8393\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 382ms/step - accuracy: 0.4992 - loss: 1.1621 - val_accuracy: 0.1953 - val_loss: 3.7015\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 379ms/step - accuracy: 0.6006 - loss: 0.9800 - val_accuracy: 0.3047 - val_loss: 3.9746\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 351ms/step - accuracy: 0.6320 - loss: 0.9355 - val_accuracy: 0.3203 - val_loss: 7.8642\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 364ms/step - accuracy: 0.6878 - loss: 0.8216 - val_accuracy: 0.3438 - val_loss: 7.5010\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 348ms/step - accuracy: 0.6709 - loss: 0.8643 - val_accuracy: 0.3672 - val_loss: 6.7293\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 352ms/step - accuracy: 0.7181 - loss: 0.7697 - val_accuracy: 0.3750 - val_loss: 5.9134\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 369ms/step - accuracy: 0.7752 - loss: 0.6808 - val_accuracy: 0.4531 - val_loss: 4.3435\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 354ms/step - accuracy: 0.7400 - loss: 0.8154 - val_accuracy: 0.4453 - val_loss: 5.7037\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 182ms/step - accuracy: 0.1979 - loss: 5.3776\n",
      "Validation accuracy for fold 3 of Front: 20.31%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 264ms/step\n",
      "\n",
      "Starting fold 4 for orientation Front\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 500ms/step - accuracy: 0.2614 - loss: 4.5797 - val_accuracy: 0.1719 - val_loss: 5.1862\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - accuracy: 0.3762 - loss: 1.4186 - val_accuracy: 0.1719 - val_loss: 5.8667\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 380ms/step - accuracy: 0.5529 - loss: 1.1014 - val_accuracy: 0.1875 - val_loss: 5.6991\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 397ms/step - accuracy: 0.6067 - loss: 0.9262 - val_accuracy: 0.3203 - val_loss: 5.3546\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 375ms/step - accuracy: 0.6590 - loss: 0.8246 - val_accuracy: 0.2734 - val_loss: 3.8588\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 382ms/step - accuracy: 0.6711 - loss: 0.9526 - val_accuracy: 0.3984 - val_loss: 5.2776\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 387ms/step - accuracy: 0.7990 - loss: 0.6591 - val_accuracy: 0.5078 - val_loss: 4.5943\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - accuracy: 0.7138 - loss: 0.7301 - val_accuracy: 0.4766 - val_loss: 2.2509\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 375ms/step - accuracy: 0.7117 - loss: 1.0425 - val_accuracy: 0.4844 - val_loss: 1.7791\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 346ms/step - accuracy: 0.7652 - loss: 0.7010 - val_accuracy: 0.5312 - val_loss: 2.4056\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 335ms/step - accuracy: 0.8214 - loss: 0.5294 - val_accuracy: 0.5625 - val_loss: 1.6414\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 355ms/step - accuracy: 0.7953 - loss: 0.5141 - val_accuracy: 0.4766 - val_loss: 3.5644\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 344ms/step - accuracy: 0.7662 - loss: 1.3486 - val_accuracy: 0.5469 - val_loss: 2.5272\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 371ms/step - accuracy: 0.8397 - loss: 0.4712 - val_accuracy: 0.5781 - val_loss: 2.2331\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 373ms/step - accuracy: 0.7444 - loss: 0.7427 - val_accuracy: 0.5547 - val_loss: 2.2861\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 380ms/step - accuracy: 0.7738 - loss: 0.7356 - val_accuracy: 0.6172 - val_loss: 2.5590\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 365ms/step - accuracy: 0.8720 - loss: 0.6067 - val_accuracy: 0.5234 - val_loss: 3.4775\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 367ms/step - accuracy: 0.8219 - loss: 0.6709 - val_accuracy: 0.4688 - val_loss: 5.4663\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 361ms/step - accuracy: 0.8069 - loss: 0.5661 - val_accuracy: 0.4766 - val_loss: 6.3842\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 378ms/step - accuracy: 0.8157 - loss: 0.5622 - val_accuracy: 0.4141 - val_loss: 11.1267\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 360ms/step - accuracy: 0.7789 - loss: 0.7052 - val_accuracy: 0.4766 - val_loss: 7.8956\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 231ms/step - accuracy: 0.5646 - loss: 1.6579\n",
      "Validation accuracy for fold 4 of Front: 56.25%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 219ms/step\n",
      "\n",
      "Starting fold 5 for orientation Front\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 478ms/step - accuracy: 0.2280 - loss: 5.3293 - val_accuracy: 0.2578 - val_loss: 2.0417\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 342ms/step - accuracy: 0.3786 - loss: 1.4892 - val_accuracy: 0.1719 - val_loss: 5.1557\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 368ms/step - accuracy: 0.5673 - loss: 1.0817 - val_accuracy: 0.1875 - val_loss: 4.8725\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 375ms/step - accuracy: 0.6254 - loss: 0.9708 - val_accuracy: 0.2266 - val_loss: 4.4010\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 384ms/step - accuracy: 0.5736 - loss: 0.9660 - val_accuracy: 0.2578 - val_loss: 4.3870\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 384ms/step - accuracy: 0.6492 - loss: 0.8292 - val_accuracy: 0.2656 - val_loss: 3.4075\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 372ms/step - accuracy: 0.6533 - loss: 0.8033 - val_accuracy: 0.3594 - val_loss: 2.4987\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 390ms/step - accuracy: 0.6828 - loss: 0.7568 - val_accuracy: 0.3594 - val_loss: 3.3518\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 383ms/step - accuracy: 0.7193 - loss: 0.6861 - val_accuracy: 0.2812 - val_loss: 4.6228\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 382ms/step - accuracy: 0.7217 - loss: 0.6311 - val_accuracy: 0.4141 - val_loss: 3.6678\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250ms/step - accuracy: 0.2354 - loss: 2.1068\n",
      "Validation accuracy for fold 5 of Front: 25.78%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 246ms/step\n",
      "\n",
      "Average validation accuracy for Front: 29.62%\n",
      "\n",
      "Training model for orientation: Up\n",
      "\n",
      "Starting fold 1 for orientation Up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 508ms/step - accuracy: 0.2348 - loss: 4.5085 - val_accuracy: 0.1938 - val_loss: 3.4650\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 380ms/step - accuracy: 0.4593 - loss: 1.3735 - val_accuracy: 0.2791 - val_loss: 2.3456\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 372ms/step - accuracy: 0.4818 - loss: 1.2225 - val_accuracy: 0.2558 - val_loss: 4.4209\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 376ms/step - accuracy: 0.5701 - loss: 1.1097 - val_accuracy: 0.1628 - val_loss: 15.4395\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 380ms/step - accuracy: 0.6581 - loss: 1.0331 - val_accuracy: 0.1628 - val_loss: 16.8015\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - accuracy: 0.7222 - loss: 0.7393 - val_accuracy: 0.1705 - val_loss: 11.0642\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 393ms/step - accuracy: 0.7248 - loss: 0.8046 - val_accuracy: 0.3178 - val_loss: 5.1598\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 357ms/step - accuracy: 0.6695 - loss: 0.9015 - val_accuracy: 0.4109 - val_loss: 3.5640\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 393ms/step - accuracy: 0.6652 - loss: 0.7996 - val_accuracy: 0.4574 - val_loss: 3.6763\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 390ms/step - accuracy: 0.7007 - loss: 0.9196 - val_accuracy: 0.3256 - val_loss: 4.2604\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 158ms/step - accuracy: 0.2013 - loss: 3.5136\n",
      "Validation accuracy for fold 1 of Up: 19.38%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 506ms/step\n",
      "\n",
      "Starting fold 2 for orientation Up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 497ms/step - accuracy: 0.2442 - loss: 5.1984 - val_accuracy: 0.1705 - val_loss: 6.9262\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 371ms/step - accuracy: 0.4161 - loss: 1.4862 - val_accuracy: 0.3178 - val_loss: 4.1259\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 365ms/step - accuracy: 0.5296 - loss: 1.1094 - val_accuracy: 0.2481 - val_loss: 4.8704\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 375ms/step - accuracy: 0.5107 - loss: 1.1307 - val_accuracy: 0.3953 - val_loss: 3.6990\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 372ms/step - accuracy: 0.5285 - loss: 1.0873 - val_accuracy: 0.4496 - val_loss: 1.8712\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 386ms/step - accuracy: 0.5749 - loss: 1.1067 - val_accuracy: 0.4496 - val_loss: 1.4162\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 369ms/step - accuracy: 0.5776 - loss: 1.1615 - val_accuracy: 0.4496 - val_loss: 2.2793\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 383ms/step - accuracy: 0.6006 - loss: 0.9745 - val_accuracy: 0.4651 - val_loss: 2.2342\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 395ms/step - accuracy: 0.6702 - loss: 0.9220 - val_accuracy: 0.5426 - val_loss: 1.6087\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 377ms/step - accuracy: 0.6580 - loss: 0.9779 - val_accuracy: 0.5969 - val_loss: 1.5849\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 380ms/step - accuracy: 0.6744 - loss: 0.8939 - val_accuracy: 0.4109 - val_loss: 2.5669\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 374ms/step - accuracy: 0.6609 - loss: 0.9483 - val_accuracy: 0.5116 - val_loss: 2.8174\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 355ms/step - accuracy: 0.6199 - loss: 0.9417 - val_accuracy: 0.2713 - val_loss: 6.2565\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 363ms/step - accuracy: 0.6758 - loss: 0.9164 - val_accuracy: 0.3643 - val_loss: 6.0918\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 363ms/step - accuracy: 0.7263 - loss: 0.7067 - val_accuracy: 0.3643 - val_loss: 3.9000\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 380ms/step - accuracy: 0.7758 - loss: 0.6580 - val_accuracy: 0.3798 - val_loss: 4.4807\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 175ms/step - accuracy: 0.4350 - loss: 1.4593\n",
      "Validation accuracy for fold 2 of Up: 44.96%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 967ms/step\n",
      "\n",
      "Starting fold 3 for orientation Up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 532ms/step - accuracy: 0.2391 - loss: 5.6254 - val_accuracy: 0.1719 - val_loss: 4.0703\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 364ms/step - accuracy: 0.3354 - loss: 1.5403 - val_accuracy: 0.2031 - val_loss: 3.5236\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 377ms/step - accuracy: 0.4472 - loss: 1.2775 - val_accuracy: 0.2344 - val_loss: 3.2266\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 381ms/step - accuracy: 0.4600 - loss: 1.1768 - val_accuracy: 0.2500 - val_loss: 3.1368\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 376ms/step - accuracy: 0.5222 - loss: 1.0453 - val_accuracy: 0.2031 - val_loss: 3.7837\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 386ms/step - accuracy: 0.5998 - loss: 0.9861 - val_accuracy: 0.1953 - val_loss: 3.4078\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 405ms/step - accuracy: 0.6559 - loss: 0.8368 - val_accuracy: 0.3984 - val_loss: 1.5323\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 385ms/step - accuracy: 0.5732 - loss: 1.0406 - val_accuracy: 0.1797 - val_loss: 11.4702\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 396ms/step - accuracy: 0.6570 - loss: 0.8880 - val_accuracy: 0.2578 - val_loss: 7.6586\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 368ms/step - accuracy: 0.7137 - loss: 0.7473 - val_accuracy: 0.2969 - val_loss: 6.2331\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 191ms/step - accuracy: 0.1833 - loss: 4.1802\n",
      "Validation accuracy for fold 3 of Up: 17.19%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 228ms/step\n",
      "\n",
      "Starting fold 4 for orientation Up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 528ms/step - accuracy: 0.2435 - loss: 5.3038 - val_accuracy: 0.1797 - val_loss: 3.9815\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 428ms/step - accuracy: 0.4053 - loss: 1.4178 - val_accuracy: 0.2031 - val_loss: 4.3240\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 398ms/step - accuracy: 0.4065 - loss: 1.4039 - val_accuracy: 0.2031 - val_loss: 3.8148\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 419ms/step - accuracy: 0.5054 - loss: 1.1723 - val_accuracy: 0.2266 - val_loss: 3.0808\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 395ms/step - accuracy: 0.5937 - loss: 0.9986 - val_accuracy: 0.2344 - val_loss: 2.2185\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - accuracy: 0.6073 - loss: 1.0191 - val_accuracy: 0.3125 - val_loss: 2.1849\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 395ms/step - accuracy: 0.6499 - loss: 0.9060 - val_accuracy: 0.4297 - val_loss: 1.8780\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 413ms/step - accuracy: 0.6531 - loss: 0.9397 - val_accuracy: 0.2812 - val_loss: 2.6188\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 407ms/step - accuracy: 0.6729 - loss: 0.7772 - val_accuracy: 0.3984 - val_loss: 2.9733\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 392ms/step - accuracy: 0.7474 - loss: 0.6440 - val_accuracy: 0.4844 - val_loss: 2.7924\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 214ms/step - accuracy: 0.1813 - loss: 4.0159\n",
      "Validation accuracy for fold 4 of Up: 17.97%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 245ms/step\n",
      "\n",
      "Starting fold 5 for orientation Up\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 547ms/step - accuracy: 0.2587 - loss: 4.1741 - val_accuracy: 0.2031 - val_loss: 3.1893\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 391ms/step - accuracy: 0.5118 - loss: 1.2690 - val_accuracy: 0.2344 - val_loss: 3.2245\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 395ms/step - accuracy: 0.4958 - loss: 1.2108 - val_accuracy: 0.2422 - val_loss: 2.9881\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 379ms/step - accuracy: 0.5667 - loss: 1.0724 - val_accuracy: 0.3359 - val_loss: 2.4311\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 355ms/step - accuracy: 0.5562 - loss: 1.0363 - val_accuracy: 0.3047 - val_loss: 6.2501\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 386ms/step - accuracy: 0.5879 - loss: 0.9360 - val_accuracy: 0.3281 - val_loss: 6.0200\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 393ms/step - accuracy: 0.7167 - loss: 0.7837 - val_accuracy: 0.3281 - val_loss: 5.7146\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 383ms/step - accuracy: 0.7508 - loss: 0.6816 - val_accuracy: 0.3828 - val_loss: 2.2566\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 385ms/step - accuracy: 0.6721 - loss: 0.9318 - val_accuracy: 0.3672 - val_loss: 2.1393\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 389ms/step - accuracy: 0.5808 - loss: 1.0974 - val_accuracy: 0.3594 - val_loss: 2.8977\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 218ms/step - accuracy: 0.1750 - loss: 3.4828\n",
      "Validation accuracy for fold 5 of Up: 20.31%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 200ms/step\n",
      "\n",
      "Average validation accuracy for Up: 23.96%\n",
      "\n",
      "Training model for orientation: Down\n",
      "\n",
      "Starting fold 1 for orientation Down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 486ms/step - accuracy: 0.2151 - loss: 6.5677 - val_accuracy: 0.1628 - val_loss: 2.7144\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 358ms/step - accuracy: 0.2773 - loss: 1.7052 - val_accuracy: 0.2481 - val_loss: 1.7371\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 385ms/step - accuracy: 0.2644 - loss: 1.5462 - val_accuracy: 0.1783 - val_loss: 2.3069\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 369ms/step - accuracy: 0.3720 - loss: 1.4971 - val_accuracy: 0.3023 - val_loss: 1.6418\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 353ms/step - accuracy: 0.3915 - loss: 1.3305 - val_accuracy: 0.2868 - val_loss: 2.0078\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 345ms/step - accuracy: 0.4119 - loss: 1.2887 - val_accuracy: 0.2868 - val_loss: 2.8117\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 346ms/step - accuracy: 0.4413 - loss: 1.2215 - val_accuracy: 0.2946 - val_loss: 2.4943\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 349ms/step - accuracy: 0.4665 - loss: 1.2079 - val_accuracy: 0.2713 - val_loss: 2.9495\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 359ms/step - accuracy: 0.5035 - loss: 1.2161 - val_accuracy: 0.3411 - val_loss: 1.9970\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 370ms/step - accuracy: 0.4838 - loss: 1.1632 - val_accuracy: 0.3488 - val_loss: 1.7394\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 177ms/step - accuracy: 0.1489 - loss: 2.7160\n",
      "Validation accuracy for fold 1 of Down: 16.28%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 463ms/step\n",
      "\n",
      "Starting fold 2 for orientation Down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 503ms/step - accuracy: 0.2000 - loss: 5.9584 - val_accuracy: 0.3101 - val_loss: 1.6356\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 353ms/step - accuracy: 0.3292 - loss: 1.6523 - val_accuracy: 0.4031 - val_loss: 1.5704\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 384ms/step - accuracy: 0.3490 - loss: 1.4842 - val_accuracy: 0.3023 - val_loss: 1.5276\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 385ms/step - accuracy: 0.3203 - loss: 1.4680 - val_accuracy: 0.3953 - val_loss: 1.8028\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 381ms/step - accuracy: 0.3748 - loss: 1.3129 - val_accuracy: 0.3798 - val_loss: 1.5354\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 391ms/step - accuracy: 0.3861 - loss: 1.3219 - val_accuracy: 0.3953 - val_loss: 1.3141\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 395ms/step - accuracy: 0.3843 - loss: 1.3571 - val_accuracy: 0.3643 - val_loss: 1.9010\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 370ms/step - accuracy: 0.4281 - loss: 1.2134 - val_accuracy: 0.3411 - val_loss: 2.0621\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 371ms/step - accuracy: 0.5471 - loss: 1.1664 - val_accuracy: 0.3411 - val_loss: 1.8210\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 346ms/step - accuracy: 0.4878 - loss: 1.2102 - val_accuracy: 0.3023 - val_loss: 1.9099\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 362ms/step - accuracy: 0.4175 - loss: 1.4472 - val_accuracy: 0.2171 - val_loss: 3.9106\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 365ms/step - accuracy: 0.3592 - loss: 1.3696 - val_accuracy: 0.2171 - val_loss: 3.2565\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 405ms/step - accuracy: 0.4014 - loss: 1.3202 - val_accuracy: 0.2326 - val_loss: 2.6974\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 382ms/step - accuracy: 0.4389 - loss: 1.1890 - val_accuracy: 0.2713 - val_loss: 2.3910\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 382ms/step - accuracy: 0.5001 - loss: 1.1132 - val_accuracy: 0.2171 - val_loss: 2.5306\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 377ms/step - accuracy: 0.5577 - loss: 1.0765 - val_accuracy: 0.2403 - val_loss: 2.6298\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 184ms/step - accuracy: 0.3701 - loss: 1.3567\n",
      "Validation accuracy for fold 2 of Down: 39.53%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 575ms/step\n",
      "\n",
      "Starting fold 3 for orientation Down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 613ms/step - accuracy: 0.2036 - loss: 5.5019 - val_accuracy: 0.1719 - val_loss: 5.3212\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 381ms/step - accuracy: 0.3695 - loss: 1.4994 - val_accuracy: 0.1719 - val_loss: 7.1976\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 363ms/step - accuracy: 0.4031 - loss: 1.3366 - val_accuracy: 0.2109 - val_loss: 4.8433\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 371ms/step - accuracy: 0.4445 - loss: 1.3382 - val_accuracy: 0.2891 - val_loss: 4.5749\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 369ms/step - accuracy: 0.4532 - loss: 1.2465 - val_accuracy: 0.2500 - val_loss: 4.8173\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 387ms/step - accuracy: 0.5484 - loss: 1.1378 - val_accuracy: 0.2656 - val_loss: 3.1097\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 365ms/step - accuracy: 0.5604 - loss: 1.0487 - val_accuracy: 0.2812 - val_loss: 1.9402\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 379ms/step - accuracy: 0.6069 - loss: 0.9600 - val_accuracy: 0.3516 - val_loss: 2.2708\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 368ms/step - accuracy: 0.6282 - loss: 0.9654 - val_accuracy: 0.2500 - val_loss: 2.9826\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 336ms/step - accuracy: 0.7260 - loss: 0.7624 - val_accuracy: 0.3438 - val_loss: 3.4802\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 268ms/step - accuracy: 0.1719 - loss: 5.3400\n",
      "Validation accuracy for fold 3 of Down: 17.19%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 199ms/step\n",
      "\n",
      "Starting fold 4 for orientation Down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 500ms/step - accuracy: 0.2051 - loss: 5.0316 - val_accuracy: 0.1719 - val_loss: 2.3842\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 375ms/step - accuracy: 0.3331 - loss: 1.5876 - val_accuracy: 0.2344 - val_loss: 2.5909\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 365ms/step - accuracy: 0.2947 - loss: 1.5502 - val_accuracy: 0.1719 - val_loss: 3.7777\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 336ms/step - accuracy: 0.3835 - loss: 1.4061 - val_accuracy: 0.1875 - val_loss: 3.3946\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 390ms/step - accuracy: 0.4268 - loss: 1.3085 - val_accuracy: 0.2812 - val_loss: 2.9770\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 374ms/step - accuracy: 0.4752 - loss: 1.2793 - val_accuracy: 0.2656 - val_loss: 3.6076\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 378ms/step - accuracy: 0.5090 - loss: 1.2505 - val_accuracy: 0.2969 - val_loss: 2.3441\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 384ms/step - accuracy: 0.4905 - loss: 1.1496 - val_accuracy: 0.2969 - val_loss: 2.6122\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 380ms/step - accuracy: 0.4446 - loss: 1.2124 - val_accuracy: 0.3125 - val_loss: 1.9265\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 389ms/step - accuracy: 0.4467 - loss: 1.1862 - val_accuracy: 0.3828 - val_loss: 1.3840\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 250ms/step - accuracy: 0.1458 - loss: 2.4456\n",
      "Validation accuracy for fold 4 of Down: 17.19%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 196ms/step\n",
      "\n",
      "Starting fold 5 for orientation Down\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 496ms/step - accuracy: 0.1927 - loss: 5.7238 - val_accuracy: 0.1641 - val_loss: 4.9768\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 364ms/step - accuracy: 0.3178 - loss: 1.5610 - val_accuracy: 0.1641 - val_loss: 11.4070\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 380ms/step - accuracy: 0.4236 - loss: 1.2495 - val_accuracy: 0.1641 - val_loss: 7.9959\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 372ms/step - accuracy: 0.4323 - loss: 1.3711 - val_accuracy: 0.1641 - val_loss: 9.5222\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 384ms/step - accuracy: 0.3956 - loss: 1.3432 - val_accuracy: 0.2188 - val_loss: 9.3834\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 362ms/step - accuracy: 0.4361 - loss: 1.2026 - val_accuracy: 0.1719 - val_loss: 11.6387\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 363ms/step - accuracy: 0.4933 - loss: 1.1655 - val_accuracy: 0.1641 - val_loss: 11.4368\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 364ms/step - accuracy: 0.5855 - loss: 0.9830 - val_accuracy: 0.1719 - val_loss: 9.1797\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 385ms/step - accuracy: 0.5359 - loss: 1.0920 - val_accuracy: 0.1641 - val_loss: 7.0828\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 381ms/step - accuracy: 0.4905 - loss: 1.1761 - val_accuracy: 0.2109 - val_loss: 5.3938\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 213ms/step - accuracy: 0.1531 - loss: 4.8332\n",
      "Validation accuracy for fold 5 of Down: 16.41%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 212ms/step\n",
      "\n",
      "Average validation accuracy for Down: 21.32%\n",
      "Training and evaluation complete for all orientations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\devar\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming emotion_labels is a list of emotion labels\n",
    "emotion_labels = ['NE', 'SA', 'SM', 'SO', 'SU', 'YN']\n",
    "\n",
    "# Model selection: MobileNetV2\n",
    "model_choice = 'MobileNetV2'\n",
    "\n",
    "# Early stopping callback with patience\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train and evaluate model for each orientation with cross-validation\n",
    "results = {}\n",
    "\n",
    "for ori_name, (data, labels) in orientation_data.items():\n",
    "    print(f\"\\nTraining model for orientation: {ori_name}\")\n",
    "    \n",
    "    # Reshape data and convert labels to one-hot encoding\n",
    "    data = data.reshape(-1, 224, 224, 3)\n",
    "    labels_one_hot = to_categorical(labels, num_classes=len(emotion_labels))\n",
    "    \n",
    "    # Stratified K-Fold Cross-Validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    orientation_accuracies = []\n",
    "    orientation_reports = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(data, labels)):\n",
    "        print(f\"\\nStarting fold {fold + 1} for orientation {ori_name}\")\n",
    "        \n",
    "        # Split data into training and validation sets for the fold\n",
    "        X_train, X_val = data[train_idx], data[val_idx]\n",
    "        y_train, y_val = labels_one_hot[train_idx], labels_one_hot[val_idx]\n",
    "        \n",
    "        # Choose base model: MobileNetV2\n",
    "        if model_choice == 'MobileNetV2':\n",
    "            base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "        # Unfreeze some layers of the base model\n",
    "        base_model.trainable = True\n",
    "        fine_tune_at = 100\n",
    "        for layer in base_model.layers[:fine_tune_at]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        # Add custom layers on top\n",
    "        x = Flatten()(base_model.output)\n",
    "        x = Dense(128, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)\n",
    "        output = Dense(len(emotion_labels), activation='softmax')(x)\n",
    "        model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0005), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model with early stopping\n",
    "        history = model.fit(X_train, y_train, epochs=30, batch_size=32, validation_data=(X_val, y_val), \n",
    "                            callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=1)\n",
    "        print(f\"Validation accuracy for fold {fold + 1} of {ori_name}: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "        # Generate a classification report for the fold\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_val_classes = np.argmax(y_val, axis=1)\n",
    "        report = classification_report(y_val_classes, y_pred_classes, target_names=emotion_labels, output_dict=True)\n",
    "        \n",
    "        # Store accuracy and report for each fold\n",
    "        orientation_accuracies.append(val_accuracy)\n",
    "        orientation_reports.append(report)\n",
    "\n",
    "    # Store results for each orientation\n",
    "    avg_accuracy = np.mean(orientation_accuracies)\n",
    "    results[ori_name] = {\n",
    "        'avg_accuracy': avg_accuracy,\n",
    "        'classification_reports': orientation_reports\n",
    "    }\n",
    "\n",
    "    print(f\"\\nAverage validation accuracy for {ori_name}: {avg_accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"Training and evaluation complete for all orientations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fc99386-cbd1-4ee8-927c-741522ec1a14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for orientation: Front\n",
      "\n",
      "Starting fold 1 for orientation Front\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 688ms/step - accuracy: 0.1774 - loss: 2.1215 - val_accuracy: 0.2171 - val_loss: 1.7163\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 491ms/step - accuracy: 0.2620 - loss: 1.8387 - val_accuracy: 0.3333 - val_loss: 1.6497\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 488ms/step - accuracy: 0.3243 - loss: 1.6761 - val_accuracy: 0.3488 - val_loss: 1.6000\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 487ms/step - accuracy: 0.3830 - loss: 1.5562 - val_accuracy: 0.3721 - val_loss: 1.5714\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 490ms/step - accuracy: 0.3305 - loss: 1.5893 - val_accuracy: 0.3876 - val_loss: 1.5560\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 492ms/step - accuracy: 0.4068 - loss: 1.4927 - val_accuracy: 0.4031 - val_loss: 1.5326\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 504ms/step - accuracy: 0.4380 - loss: 1.4272 - val_accuracy: 0.3876 - val_loss: 1.5208\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 511ms/step - accuracy: 0.4361 - loss: 1.4223 - val_accuracy: 0.4264 - val_loss: 1.4972\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 504ms/step - accuracy: 0.4412 - loss: 1.3797 - val_accuracy: 0.4186 - val_loss: 1.4794\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 502ms/step - accuracy: 0.4919 - loss: 1.3358 - val_accuracy: 0.3953 - val_loss: 1.4746\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 512ms/step - accuracy: 0.4985 - loss: 1.3326 - val_accuracy: 0.4109 - val_loss: 1.4603\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 505ms/step - accuracy: 0.4879 - loss: 1.3186 - val_accuracy: 0.4574 - val_loss: 1.4464\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 504ms/step - accuracy: 0.5063 - loss: 1.3222 - val_accuracy: 0.4419 - val_loss: 1.4372\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 497ms/step - accuracy: 0.4621 - loss: 1.3211 - val_accuracy: 0.4341 - val_loss: 1.4404\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 498ms/step - accuracy: 0.4943 - loss: 1.2744 - val_accuracy: 0.4806 - val_loss: 1.4114\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 494ms/step - accuracy: 0.5191 - loss: 1.2201 - val_accuracy: 0.4884 - val_loss: 1.4131\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 472ms/step - accuracy: 0.5013 - loss: 1.2826 - val_accuracy: 0.4651 - val_loss: 1.3955\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 497ms/step - accuracy: 0.5225 - loss: 1.2091 - val_accuracy: 0.4729 - val_loss: 1.3944\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 493ms/step - accuracy: 0.5629 - loss: 1.1925 - val_accuracy: 0.4651 - val_loss: 1.3788\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 495ms/step - accuracy: 0.5682 - loss: 1.2161 - val_accuracy: 0.4884 - val_loss: 1.3650\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 503ms/step - accuracy: 0.5780 - loss: 1.1481 - val_accuracy: 0.4496 - val_loss: 1.3726\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 498ms/step - accuracy: 0.5500 - loss: 1.1735 - val_accuracy: 0.4574 - val_loss: 1.3626\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 499ms/step - accuracy: 0.5734 - loss: 1.1562 - val_accuracy: 0.4574 - val_loss: 1.3521\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 487ms/step - accuracy: 0.6265 - loss: 1.0553 - val_accuracy: 0.4806 - val_loss: 1.3464\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 497ms/step - accuracy: 0.6052 - loss: 1.0781 - val_accuracy: 0.4496 - val_loss: 1.3387\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 491ms/step - accuracy: 0.6368 - loss: 1.0320 - val_accuracy: 0.4961 - val_loss: 1.3473\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 501ms/step - accuracy: 0.6094 - loss: 1.0782 - val_accuracy: 0.4729 - val_loss: 1.3463\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 500ms/step - accuracy: 0.6141 - loss: 1.1075 - val_accuracy: 0.4496 - val_loss: 1.3421\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 486ms/step - accuracy: 0.6333 - loss: 1.0539 - val_accuracy: 0.4961 - val_loss: 1.3253\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 483ms/step - accuracy: 0.6561 - loss: 1.0095 - val_accuracy: 0.4884 - val_loss: 1.3465\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 314ms/step - accuracy: 0.5330 - loss: 1.2977\n",
      "Validation accuracy for fold 1 of Front: 48.84%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 943ms/step\n",
      "\n",
      "Starting fold 2 for orientation Front\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 703ms/step - accuracy: 0.1804 - loss: 2.0506 - val_accuracy: 0.3333 - val_loss: 1.6714\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 484ms/step - accuracy: 0.2489 - loss: 1.8487 - val_accuracy: 0.3333 - val_loss: 1.6094\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 490ms/step - accuracy: 0.2997 - loss: 1.6965 - val_accuracy: 0.3953 - val_loss: 1.5348\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 488ms/step - accuracy: 0.3733 - loss: 1.5783 - val_accuracy: 0.4031 - val_loss: 1.5099\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 492ms/step - accuracy: 0.3601 - loss: 1.5490 - val_accuracy: 0.4186 - val_loss: 1.4612\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 507ms/step - accuracy: 0.4423 - loss: 1.4435 - val_accuracy: 0.4419 - val_loss: 1.4419\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 502ms/step - accuracy: 0.4053 - loss: 1.4580 - val_accuracy: 0.4574 - val_loss: 1.4023\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 497ms/step - accuracy: 0.4477 - loss: 1.4153 - val_accuracy: 0.4419 - val_loss: 1.4031\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 493ms/step - accuracy: 0.4136 - loss: 1.3831 - val_accuracy: 0.5271 - val_loss: 1.3648\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 502ms/step - accuracy: 0.4393 - loss: 1.3795 - val_accuracy: 0.5039 - val_loss: 1.3771\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 502ms/step - accuracy: 0.4400 - loss: 1.3983 - val_accuracy: 0.5039 - val_loss: 1.3669\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 500ms/step - accuracy: 0.5120 - loss: 1.2923 - val_accuracy: 0.4884 - val_loss: 1.3488\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 508ms/step - accuracy: 0.4866 - loss: 1.3079 - val_accuracy: 0.5039 - val_loss: 1.3252\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 486ms/step - accuracy: 0.5309 - loss: 1.2629 - val_accuracy: 0.5271 - val_loss: 1.3104\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 479ms/step - accuracy: 0.4855 - loss: 1.2942 - val_accuracy: 0.5271 - val_loss: 1.2931\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 475ms/step - accuracy: 0.4968 - loss: 1.2438 - val_accuracy: 0.5194 - val_loss: 1.2762\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 475ms/step - accuracy: 0.5598 - loss: 1.1877 - val_accuracy: 0.5349 - val_loss: 1.2646\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 470ms/step - accuracy: 0.5365 - loss: 1.2275 - val_accuracy: 0.5271 - val_loss: 1.2574\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 473ms/step - accuracy: 0.5684 - loss: 1.2008 - val_accuracy: 0.5659 - val_loss: 1.2479\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 455ms/step - accuracy: 0.5141 - loss: 1.1983 - val_accuracy: 0.5504 - val_loss: 1.2291\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 469ms/step - accuracy: 0.5804 - loss: 1.1217 - val_accuracy: 0.5194 - val_loss: 1.2429\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 461ms/step - accuracy: 0.5524 - loss: 1.1433 - val_accuracy: 0.5349 - val_loss: 1.2163\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 467ms/step - accuracy: 0.5754 - loss: 1.1622 - val_accuracy: 0.5194 - val_loss: 1.2353\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 479ms/step - accuracy: 0.5866 - loss: 1.1050 - val_accuracy: 0.5426 - val_loss: 1.2201\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 485ms/step - accuracy: 0.5786 - loss: 1.1207 - val_accuracy: 0.5891 - val_loss: 1.1892\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 493ms/step - accuracy: 0.5923 - loss: 1.0955 - val_accuracy: 0.5271 - val_loss: 1.2043\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 473ms/step - accuracy: 0.5966 - loss: 1.0788 - val_accuracy: 0.5426 - val_loss: 1.1888\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 488ms/step - accuracy: 0.6361 - loss: 1.0212 - val_accuracy: 0.5426 - val_loss: 1.1903\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 496ms/step - accuracy: 0.6325 - loss: 1.0350 - val_accuracy: 0.5814 - val_loss: 1.1725\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 496ms/step - accuracy: 0.6156 - loss: 1.0483 - val_accuracy: 0.5504 - val_loss: 1.1608\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 317ms/step - accuracy: 0.5220 - loss: 1.1738\n",
      "Validation accuracy for fold 2 of Front: 55.04%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step  \n",
      "\n",
      "Starting fold 3 for orientation Front\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 727ms/step - accuracy: 0.1695 - loss: 2.0438 - val_accuracy: 0.3047 - val_loss: 1.7206\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 490ms/step - accuracy: 0.2712 - loss: 1.7355 - val_accuracy: 0.3047 - val_loss: 1.6554\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 495ms/step - accuracy: 0.2736 - loss: 1.6934 - val_accuracy: 0.2969 - val_loss: 1.6285\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 491ms/step - accuracy: 0.3737 - loss: 1.5614 - val_accuracy: 0.3750 - val_loss: 1.5924\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 494ms/step - accuracy: 0.3216 - loss: 1.6011 - val_accuracy: 0.2891 - val_loss: 1.5450\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 488ms/step - accuracy: 0.4146 - loss: 1.5094 - val_accuracy: 0.3828 - val_loss: 1.5125\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 498ms/step - accuracy: 0.4272 - loss: 1.4649 - val_accuracy: 0.3906 - val_loss: 1.5018\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 487ms/step - accuracy: 0.4489 - loss: 1.4006 - val_accuracy: 0.4297 - val_loss: 1.4911\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 493ms/step - accuracy: 0.5106 - loss: 1.3529 - val_accuracy: 0.4219 - val_loss: 1.4721\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 493ms/step - accuracy: 0.4800 - loss: 1.3329 - val_accuracy: 0.4141 - val_loss: 1.4669\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 489ms/step - accuracy: 0.5069 - loss: 1.3228 - val_accuracy: 0.4219 - val_loss: 1.4533\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 491ms/step - accuracy: 0.4877 - loss: 1.2981 - val_accuracy: 0.3906 - val_loss: 1.4383\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 486ms/step - accuracy: 0.5095 - loss: 1.3116 - val_accuracy: 0.4531 - val_loss: 1.4234\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 488ms/step - accuracy: 0.5443 - loss: 1.2326 - val_accuracy: 0.4219 - val_loss: 1.4074\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 490ms/step - accuracy: 0.5399 - loss: 1.2273 - val_accuracy: 0.4297 - val_loss: 1.4019\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 490ms/step - accuracy: 0.5245 - loss: 1.2194 - val_accuracy: 0.4609 - val_loss: 1.3975\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 494ms/step - accuracy: 0.5852 - loss: 1.1405 - val_accuracy: 0.4453 - val_loss: 1.3832\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 500ms/step - accuracy: 0.5903 - loss: 1.1414 - val_accuracy: 0.4609 - val_loss: 1.3736\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 492ms/step - accuracy: 0.5341 - loss: 1.2239 - val_accuracy: 0.4375 - val_loss: 1.3738\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 494ms/step - accuracy: 0.5564 - loss: 1.1432 - val_accuracy: 0.4297 - val_loss: 1.3760\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 488ms/step - accuracy: 0.5742 - loss: 1.1153 - val_accuracy: 0.4844 - val_loss: 1.3725\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 486ms/step - accuracy: 0.5974 - loss: 1.0975 - val_accuracy: 0.4531 - val_loss: 1.3550\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 471ms/step - accuracy: 0.6273 - loss: 1.0637 - val_accuracy: 0.5078 - val_loss: 1.3498\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 478ms/step - accuracy: 0.5910 - loss: 1.0719 - val_accuracy: 0.4844 - val_loss: 1.3484\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 486ms/step - accuracy: 0.6106 - loss: 1.0481 - val_accuracy: 0.4766 - val_loss: 1.3453\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 504ms/step - accuracy: 0.6014 - loss: 1.0858 - val_accuracy: 0.4531 - val_loss: 1.3344\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 485ms/step - accuracy: 0.6354 - loss: 1.0510 - val_accuracy: 0.4766 - val_loss: 1.3345\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 493ms/step - accuracy: 0.6279 - loss: 1.0605 - val_accuracy: 0.4531 - val_loss: 1.3472\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 480ms/step - accuracy: 0.6696 - loss: 0.9932 - val_accuracy: 0.5078 - val_loss: 1.3337\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 484ms/step - accuracy: 0.6515 - loss: 1.0084 - val_accuracy: 0.4922 - val_loss: 1.3357\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 397ms/step - accuracy: 0.5115 - loss: 1.3802\n",
      "Validation accuracy for fold 3 of Front: 49.22%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 401ms/step\n",
      "\n",
      "Starting fold 4 for orientation Front\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 705ms/step - accuracy: 0.1902 - loss: 2.1151 - val_accuracy: 0.2969 - val_loss: 1.6580\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 470ms/step - accuracy: 0.2424 - loss: 1.8081 - val_accuracy: 0.4219 - val_loss: 1.5721\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 471ms/step - accuracy: 0.2975 - loss: 1.6562 - val_accuracy: 0.4453 - val_loss: 1.5279\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 475ms/step - accuracy: 0.3125 - loss: 1.6195 - val_accuracy: 0.4688 - val_loss: 1.4836\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 474ms/step - accuracy: 0.3895 - loss: 1.5409 - val_accuracy: 0.4766 - val_loss: 1.4524\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 477ms/step - accuracy: 0.4370 - loss: 1.4579 - val_accuracy: 0.5000 - val_loss: 1.4337\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 477ms/step - accuracy: 0.4620 - loss: 1.4643 - val_accuracy: 0.5000 - val_loss: 1.4093\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 479ms/step - accuracy: 0.4749 - loss: 1.3653 - val_accuracy: 0.5312 - val_loss: 1.3920\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 478ms/step - accuracy: 0.4250 - loss: 1.4255 - val_accuracy: 0.5078 - val_loss: 1.3988\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 489ms/step - accuracy: 0.5371 - loss: 1.2820 - val_accuracy: 0.5156 - val_loss: 1.3765\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 486ms/step - accuracy: 0.5050 - loss: 1.2618 - val_accuracy: 0.5078 - val_loss: 1.3512\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 472ms/step - accuracy: 0.5129 - loss: 1.2657 - val_accuracy: 0.5547 - val_loss: 1.3395\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 472ms/step - accuracy: 0.5511 - loss: 1.2357 - val_accuracy: 0.5078 - val_loss: 1.3290\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 479ms/step - accuracy: 0.5470 - loss: 1.2359 - val_accuracy: 0.4922 - val_loss: 1.3195\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 480ms/step - accuracy: 0.5232 - loss: 1.2536 - val_accuracy: 0.5234 - val_loss: 1.3141\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 471ms/step - accuracy: 0.5367 - loss: 1.1932 - val_accuracy: 0.4922 - val_loss: 1.3029\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 480ms/step - accuracy: 0.5590 - loss: 1.2041 - val_accuracy: 0.4766 - val_loss: 1.3161\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 480ms/step - accuracy: 0.5285 - loss: 1.2134 - val_accuracy: 0.5000 - val_loss: 1.2936\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 473ms/step - accuracy: 0.5935 - loss: 1.1659 - val_accuracy: 0.4844 - val_loss: 1.2861\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 478ms/step - accuracy: 0.5412 - loss: 1.1828 - val_accuracy: 0.5078 - val_loss: 1.2881\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 475ms/step - accuracy: 0.5874 - loss: 1.1319 - val_accuracy: 0.5078 - val_loss: 1.2934\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 471ms/step - accuracy: 0.6060 - loss: 1.0846 - val_accuracy: 0.4922 - val_loss: 1.2813\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 473ms/step - accuracy: 0.5919 - loss: 1.1157 - val_accuracy: 0.5078 - val_loss: 1.2743\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 476ms/step - accuracy: 0.6141 - loss: 1.0447 - val_accuracy: 0.5078 - val_loss: 1.2759\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 479ms/step - accuracy: 0.6234 - loss: 1.0724 - val_accuracy: 0.4844 - val_loss: 1.2753\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 470ms/step - accuracy: 0.6314 - loss: 1.0556 - val_accuracy: 0.5078 - val_loss: 1.2817\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 466ms/step - accuracy: 0.6448 - loss: 1.0323 - val_accuracy: 0.5000 - val_loss: 1.2706\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 471ms/step - accuracy: 0.6578 - loss: 0.9784 - val_accuracy: 0.5000 - val_loss: 1.2610\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 482ms/step - accuracy: 0.6291 - loss: 1.0027 - val_accuracy: 0.4766 - val_loss: 1.2520\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 478ms/step - accuracy: 0.6803 - loss: 0.9407 - val_accuracy: 0.4844 - val_loss: 1.2585\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 390ms/step - accuracy: 0.4656 - loss: 1.2933\n",
      "Validation accuracy for fold 4 of Front: 48.44%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 385ms/step\n",
      "\n",
      "Starting fold 5 for orientation Front\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 689ms/step - accuracy: 0.2139 - loss: 2.0097 - val_accuracy: 0.2656 - val_loss: 1.7003\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 477ms/step - accuracy: 0.2616 - loss: 1.7634 - val_accuracy: 0.3438 - val_loss: 1.6075\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 481ms/step - accuracy: 0.3067 - loss: 1.6424 - val_accuracy: 0.3672 - val_loss: 1.5715\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 488ms/step - accuracy: 0.3393 - loss: 1.6221 - val_accuracy: 0.3672 - val_loss: 1.5466\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 471ms/step - accuracy: 0.3201 - loss: 1.5990 - val_accuracy: 0.3906 - val_loss: 1.5244\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 479ms/step - accuracy: 0.4060 - loss: 1.4720 - val_accuracy: 0.3750 - val_loss: 1.5122\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 476ms/step - accuracy: 0.4207 - loss: 1.4511 - val_accuracy: 0.3906 - val_loss: 1.4954\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 489ms/step - accuracy: 0.4655 - loss: 1.4458 - val_accuracy: 0.3828 - val_loss: 1.4831\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 490ms/step - accuracy: 0.4027 - loss: 1.4042 - val_accuracy: 0.3906 - val_loss: 1.4857\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 487ms/step - accuracy: 0.4895 - loss: 1.3583 - val_accuracy: 0.4219 - val_loss: 1.4496\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 491ms/step - accuracy: 0.5183 - loss: 1.2883 - val_accuracy: 0.3984 - val_loss: 1.4439\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 483ms/step - accuracy: 0.5026 - loss: 1.3114 - val_accuracy: 0.3906 - val_loss: 1.4321\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 483ms/step - accuracy: 0.5637 - loss: 1.2360 - val_accuracy: 0.4375 - val_loss: 1.4277\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 484ms/step - accuracy: 0.5332 - loss: 1.2366 - val_accuracy: 0.4219 - val_loss: 1.4307\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 483ms/step - accuracy: 0.5718 - loss: 1.1938 - val_accuracy: 0.4375 - val_loss: 1.4139\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 482ms/step - accuracy: 0.4832 - loss: 1.2562 - val_accuracy: 0.4375 - val_loss: 1.4086\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 478ms/step - accuracy: 0.5719 - loss: 1.1658 - val_accuracy: 0.4297 - val_loss: 1.4058\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 487ms/step - accuracy: 0.5643 - loss: 1.1876 - val_accuracy: 0.4531 - val_loss: 1.3964\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 485ms/step - accuracy: 0.5591 - loss: 1.1425 - val_accuracy: 0.4219 - val_loss: 1.4126\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 488ms/step - accuracy: 0.5502 - loss: 1.1856 - val_accuracy: 0.4141 - val_loss: 1.4008\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 483ms/step - accuracy: 0.5705 - loss: 1.1159 - val_accuracy: 0.4453 - val_loss: 1.3840\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 471ms/step - accuracy: 0.6258 - loss: 1.0800 - val_accuracy: 0.4453 - val_loss: 1.3737\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 485ms/step - accuracy: 0.6279 - loss: 1.0386 - val_accuracy: 0.4531 - val_loss: 1.3758\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 478ms/step - accuracy: 0.6183 - loss: 1.0593 - val_accuracy: 0.4531 - val_loss: 1.3796\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 477ms/step - accuracy: 0.6133 - loss: 1.0505 - val_accuracy: 0.4062 - val_loss: 1.3798\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 485ms/step - accuracy: 0.6592 - loss: 1.0119 - val_accuracy: 0.4297 - val_loss: 1.3809\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 473ms/step - accuracy: 0.6402 - loss: 1.0065 - val_accuracy: 0.4531 - val_loss: 1.3815\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 483ms/step - accuracy: 0.5982 - loss: 1.0493 - val_accuracy: 0.4297 - val_loss: 1.3931\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 483ms/step - accuracy: 0.6317 - loss: 1.0153 - val_accuracy: 0.4531 - val_loss: 1.3810\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 488ms/step - accuracy: 0.6585 - loss: 0.9740 - val_accuracy: 0.4531 - val_loss: 1.3836\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 402ms/step - accuracy: 0.4333 - loss: 1.4654\n",
      "Validation accuracy for fold 5 of Front: 45.31%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 357ms/step\n",
      "\n",
      "Average validation accuracy for Front: 49.37%\n",
      "\n",
      "Training model for orientation: Up\n",
      "\n",
      "Starting fold 1 for orientation Up\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 662ms/step - accuracy: 0.1580 - loss: 2.1011 - val_accuracy: 0.2171 - val_loss: 1.7500\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 484ms/step - accuracy: 0.2272 - loss: 1.8034 - val_accuracy: 0.2946 - val_loss: 1.6826\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 478ms/step - accuracy: 0.2594 - loss: 1.7108 - val_accuracy: 0.3643 - val_loss: 1.6246\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 485ms/step - accuracy: 0.3180 - loss: 1.6135 - val_accuracy: 0.3488 - val_loss: 1.5896\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 479ms/step - accuracy: 0.3765 - loss: 1.5758 - val_accuracy: 0.4264 - val_loss: 1.5528\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 487ms/step - accuracy: 0.4303 - loss: 1.4987 - val_accuracy: 0.3876 - val_loss: 1.5252\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 473ms/step - accuracy: 0.4531 - loss: 1.4676 - val_accuracy: 0.3953 - val_loss: 1.4947\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 501ms/step - accuracy: 0.4117 - loss: 1.4486 - val_accuracy: 0.3643 - val_loss: 1.4777\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 490ms/step - accuracy: 0.4213 - loss: 1.4176 - val_accuracy: 0.4419 - val_loss: 1.4535\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 484ms/step - accuracy: 0.4712 - loss: 1.3574 - val_accuracy: 0.3566 - val_loss: 1.4502\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 483ms/step - accuracy: 0.4765 - loss: 1.3627 - val_accuracy: 0.4031 - val_loss: 1.4304\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 481ms/step - accuracy: 0.4901 - loss: 1.2956 - val_accuracy: 0.3566 - val_loss: 1.4314\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 479ms/step - accuracy: 0.4603 - loss: 1.3216 - val_accuracy: 0.4031 - val_loss: 1.4080\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 483ms/step - accuracy: 0.5273 - loss: 1.2380 - val_accuracy: 0.4264 - val_loss: 1.4108\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 502ms/step - accuracy: 0.5042 - loss: 1.3026 - val_accuracy: 0.3876 - val_loss: 1.3923\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 487ms/step - accuracy: 0.5290 - loss: 1.2019 - val_accuracy: 0.3488 - val_loss: 1.3885\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 491ms/step - accuracy: 0.5511 - loss: 1.2337 - val_accuracy: 0.3643 - val_loss: 1.3811\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 496ms/step - accuracy: 0.5522 - loss: 1.2084 - val_accuracy: 0.4031 - val_loss: 1.3581\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 495ms/step - accuracy: 0.5721 - loss: 1.1612 - val_accuracy: 0.3953 - val_loss: 1.3402\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 499ms/step - accuracy: 0.5559 - loss: 1.1615 - val_accuracy: 0.4264 - val_loss: 1.3383\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 499ms/step - accuracy: 0.6300 - loss: 1.1118 - val_accuracy: 0.4109 - val_loss: 1.3293\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 490ms/step - accuracy: 0.5831 - loss: 1.1186 - val_accuracy: 0.3798 - val_loss: 1.3368\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 483ms/step - accuracy: 0.5626 - loss: 1.1208 - val_accuracy: 0.3798 - val_loss: 1.3307\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 482ms/step - accuracy: 0.5397 - loss: 1.1316 - val_accuracy: 0.3876 - val_loss: 1.3072\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 470ms/step - accuracy: 0.5671 - loss: 1.0869 - val_accuracy: 0.3953 - val_loss: 1.3145\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 478ms/step - accuracy: 0.5939 - loss: 1.0851 - val_accuracy: 0.3798 - val_loss: 1.3127\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 481ms/step - accuracy: 0.6061 - loss: 1.0541 - val_accuracy: 0.4186 - val_loss: 1.3099\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 469ms/step - accuracy: 0.6404 - loss: 0.9903 - val_accuracy: 0.3953 - val_loss: 1.3255\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 460ms/step - accuracy: 0.6554 - loss: 0.9735 - val_accuracy: 0.4109 - val_loss: 1.3048\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 480ms/step - accuracy: 0.6023 - loss: 0.9790 - val_accuracy: 0.4109 - val_loss: 1.3104\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 302ms/step - accuracy: 0.4238 - loss: 1.3269\n",
      "Validation accuracy for fold 1 of Up: 41.09%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1s/step  \n",
      "\n",
      "Starting fold 2 for orientation Up\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 577ms/step - accuracy: 0.1962 - loss: 2.0406 - val_accuracy: 0.2403 - val_loss: 1.8020\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 415ms/step - accuracy: 0.2044 - loss: 1.8770 - val_accuracy: 0.2093 - val_loss: 1.7160\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 430ms/step - accuracy: 0.3190 - loss: 1.6313 - val_accuracy: 0.2558 - val_loss: 1.6678\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 427ms/step - accuracy: 0.3564 - loss: 1.5891 - val_accuracy: 0.2791 - val_loss: 1.6388\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 413ms/step - accuracy: 0.3542 - loss: 1.5713 - val_accuracy: 0.3256 - val_loss: 1.5986\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 424ms/step - accuracy: 0.3603 - loss: 1.5512 - val_accuracy: 0.3488 - val_loss: 1.5770\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 427ms/step - accuracy: 0.4150 - loss: 1.4611 - val_accuracy: 0.3876 - val_loss: 1.5486\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 417ms/step - accuracy: 0.4258 - loss: 1.4008 - val_accuracy: 0.3721 - val_loss: 1.5378\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 414ms/step - accuracy: 0.4538 - loss: 1.3740 - val_accuracy: 0.3876 - val_loss: 1.5206\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 415ms/step - accuracy: 0.4169 - loss: 1.4284 - val_accuracy: 0.4109 - val_loss: 1.5061\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 416ms/step - accuracy: 0.4613 - loss: 1.3453 - val_accuracy: 0.4186 - val_loss: 1.4959\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 408ms/step - accuracy: 0.5123 - loss: 1.2944 - val_accuracy: 0.3876 - val_loss: 1.4762\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 409ms/step - accuracy: 0.5225 - loss: 1.2250 - val_accuracy: 0.3721 - val_loss: 1.4810\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 411ms/step - accuracy: 0.4959 - loss: 1.3046 - val_accuracy: 0.3798 - val_loss: 1.4600\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 411ms/step - accuracy: 0.5058 - loss: 1.2660 - val_accuracy: 0.4031 - val_loss: 1.4280\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 410ms/step - accuracy: 0.4983 - loss: 1.2080 - val_accuracy: 0.4109 - val_loss: 1.4207\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 409ms/step - accuracy: 0.5166 - loss: 1.2407 - val_accuracy: 0.3953 - val_loss: 1.4142\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 412ms/step - accuracy: 0.4705 - loss: 1.2536 - val_accuracy: 0.3953 - val_loss: 1.4087\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 413ms/step - accuracy: 0.5307 - loss: 1.1855 - val_accuracy: 0.3488 - val_loss: 1.4122\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 410ms/step - accuracy: 0.5356 - loss: 1.2262 - val_accuracy: 0.4264 - val_loss: 1.3834\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 410ms/step - accuracy: 0.5577 - loss: 1.1792 - val_accuracy: 0.4496 - val_loss: 1.3709\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 405ms/step - accuracy: 0.5411 - loss: 1.1455 - val_accuracy: 0.4186 - val_loss: 1.3718\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 409ms/step - accuracy: 0.5822 - loss: 1.0850 - val_accuracy: 0.4031 - val_loss: 1.3767\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 412ms/step - accuracy: 0.5523 - loss: 1.1266 - val_accuracy: 0.4419 - val_loss: 1.3622\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 412ms/step - accuracy: 0.5529 - loss: 1.1482 - val_accuracy: 0.4341 - val_loss: 1.3477\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 413ms/step - accuracy: 0.5605 - loss: 1.1039 - val_accuracy: 0.4031 - val_loss: 1.3489\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 416ms/step - accuracy: 0.5891 - loss: 1.1024 - val_accuracy: 0.4264 - val_loss: 1.3390\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 411ms/step - accuracy: 0.5898 - loss: 1.0461 - val_accuracy: 0.4186 - val_loss: 1.3395\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 413ms/step - accuracy: 0.5994 - loss: 1.0663 - val_accuracy: 0.4109 - val_loss: 1.3384\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 413ms/step - accuracy: 0.6287 - loss: 0.9907 - val_accuracy: 0.4109 - val_loss: 1.3507\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 263ms/step - accuracy: 0.4152 - loss: 1.3621\n",
      "Validation accuracy for fold 2 of Up: 41.09%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 845ms/step\n",
      "\n",
      "Starting fold 3 for orientation Up\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 566ms/step - accuracy: 0.1712 - loss: 2.1765 - val_accuracy: 0.2188 - val_loss: 1.7692\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 403ms/step - accuracy: 0.2763 - loss: 1.8243 - val_accuracy: 0.3359 - val_loss: 1.6721\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 408ms/step - accuracy: 0.3417 - loss: 1.6326 - val_accuracy: 0.3516 - val_loss: 1.6090\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 413ms/step - accuracy: 0.3817 - loss: 1.5869 - val_accuracy: 0.3516 - val_loss: 1.5775\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 417ms/step - accuracy: 0.3923 - loss: 1.4914 - val_accuracy: 0.3516 - val_loss: 1.5544\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 414ms/step - accuracy: 0.4250 - loss: 1.4643 - val_accuracy: 0.3281 - val_loss: 1.5344\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 415ms/step - accuracy: 0.4293 - loss: 1.3999 - val_accuracy: 0.3984 - val_loss: 1.5083\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 425ms/step - accuracy: 0.4527 - loss: 1.3654 - val_accuracy: 0.3594 - val_loss: 1.5056\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 418ms/step - accuracy: 0.4297 - loss: 1.3462 - val_accuracy: 0.3984 - val_loss: 1.4989\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 418ms/step - accuracy: 0.4997 - loss: 1.3260 - val_accuracy: 0.3906 - val_loss: 1.4785\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 414ms/step - accuracy: 0.4887 - loss: 1.2926 - val_accuracy: 0.3516 - val_loss: 1.4696\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 419ms/step - accuracy: 0.5109 - loss: 1.2958 - val_accuracy: 0.3594 - val_loss: 1.4675\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 419ms/step - accuracy: 0.5226 - loss: 1.2184 - val_accuracy: 0.3906 - val_loss: 1.4502\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 410ms/step - accuracy: 0.4925 - loss: 1.2631 - val_accuracy: 0.3984 - val_loss: 1.4379\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 407ms/step - accuracy: 0.5441 - loss: 1.1828 - val_accuracy: 0.4141 - val_loss: 1.4329\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 408ms/step - accuracy: 0.5543 - loss: 1.2059 - val_accuracy: 0.3906 - val_loss: 1.4281\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 420ms/step - accuracy: 0.5362 - loss: 1.1769 - val_accuracy: 0.4141 - val_loss: 1.4256\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 405ms/step - accuracy: 0.5512 - loss: 1.1637 - val_accuracy: 0.3984 - val_loss: 1.4338\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 420ms/step - accuracy: 0.5626 - loss: 1.1613 - val_accuracy: 0.3906 - val_loss: 1.4305\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 424ms/step - accuracy: 0.5765 - loss: 1.1190 - val_accuracy: 0.3906 - val_loss: 1.4267\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 438ms/step - accuracy: 0.6170 - loss: 1.0559 - val_accuracy: 0.3828 - val_loss: 1.4219\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 416ms/step - accuracy: 0.6205 - loss: 1.0503 - val_accuracy: 0.3828 - val_loss: 1.4118\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 423ms/step - accuracy: 0.5998 - loss: 1.0627 - val_accuracy: 0.3438 - val_loss: 1.4142\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 415ms/step - accuracy: 0.5813 - loss: 1.0408 - val_accuracy: 0.3828 - val_loss: 1.4081\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 417ms/step - accuracy: 0.5691 - loss: 1.0448 - val_accuracy: 0.3750 - val_loss: 1.3969\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 418ms/step - accuracy: 0.5741 - loss: 1.0766 - val_accuracy: 0.4141 - val_loss: 1.3951\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 416ms/step - accuracy: 0.6845 - loss: 0.9429 - val_accuracy: 0.4141 - val_loss: 1.3927\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 418ms/step - accuracy: 0.6265 - loss: 0.9757 - val_accuracy: 0.4141 - val_loss: 1.4082\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 415ms/step - accuracy: 0.6340 - loss: 0.9997 - val_accuracy: 0.3984 - val_loss: 1.4082\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 418ms/step - accuracy: 0.6099 - loss: 0.9799 - val_accuracy: 0.3906 - val_loss: 1.4105\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 340ms/step - accuracy: 0.4104 - loss: 1.4337\n",
      "Validation accuracy for fold 3 of Up: 39.06%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 341ms/step\n",
      "\n",
      "Starting fold 4 for orientation Up\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 569ms/step - accuracy: 0.1786 - loss: 2.0619 - val_accuracy: 0.2188 - val_loss: 1.7109\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 409ms/step - accuracy: 0.2309 - loss: 1.8464 - val_accuracy: 0.3359 - val_loss: 1.6208\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 424ms/step - accuracy: 0.3045 - loss: 1.7317 - val_accuracy: 0.3828 - val_loss: 1.5768\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 437ms/step - accuracy: 0.3040 - loss: 1.6536 - val_accuracy: 0.4141 - val_loss: 1.5357\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 414ms/step - accuracy: 0.3431 - loss: 1.5829 - val_accuracy: 0.4141 - val_loss: 1.5036\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 418ms/step - accuracy: 0.3764 - loss: 1.5344 - val_accuracy: 0.4453 - val_loss: 1.4720\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 412ms/step - accuracy: 0.3886 - loss: 1.4944 - val_accuracy: 0.4375 - val_loss: 1.4368\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 414ms/step - accuracy: 0.4582 - loss: 1.4290 - val_accuracy: 0.4688 - val_loss: 1.4100\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 411ms/step - accuracy: 0.4773 - loss: 1.4038 - val_accuracy: 0.4453 - val_loss: 1.3902\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 421ms/step - accuracy: 0.4632 - loss: 1.3787 - val_accuracy: 0.4531 - val_loss: 1.3801\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 427ms/step - accuracy: 0.4916 - loss: 1.2817 - val_accuracy: 0.4609 - val_loss: 1.3654\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 418ms/step - accuracy: 0.4912 - loss: 1.3317 - val_accuracy: 0.4531 - val_loss: 1.3501\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 425ms/step - accuracy: 0.4553 - loss: 1.3470 - val_accuracy: 0.4453 - val_loss: 1.3368\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 418ms/step - accuracy: 0.5025 - loss: 1.2969 - val_accuracy: 0.4375 - val_loss: 1.3137\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 423ms/step - accuracy: 0.4885 - loss: 1.2386 - val_accuracy: 0.4688 - val_loss: 1.2962\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 424ms/step - accuracy: 0.4899 - loss: 1.2630 - val_accuracy: 0.4609 - val_loss: 1.3178\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 422ms/step - accuracy: 0.5162 - loss: 1.2440 - val_accuracy: 0.4766 - val_loss: 1.2941\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 419ms/step - accuracy: 0.5198 - loss: 1.2077 - val_accuracy: 0.4375 - val_loss: 1.2868\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 421ms/step - accuracy: 0.5650 - loss: 1.1613 - val_accuracy: 0.4453 - val_loss: 1.2727\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 423ms/step - accuracy: 0.5961 - loss: 1.1649 - val_accuracy: 0.4609 - val_loss: 1.2680\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 419ms/step - accuracy: 0.5854 - loss: 1.1080 - val_accuracy: 0.4531 - val_loss: 1.2641\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 423ms/step - accuracy: 0.5407 - loss: 1.1671 - val_accuracy: 0.4922 - val_loss: 1.2602\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 420ms/step - accuracy: 0.5805 - loss: 1.0699 - val_accuracy: 0.4375 - val_loss: 1.2538\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 419ms/step - accuracy: 0.5860 - loss: 1.0886 - val_accuracy: 0.4531 - val_loss: 1.2511\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 723ms/step - accuracy: 0.5977 - loss: 1.0453 - val_accuracy: 0.4453 - val_loss: 1.2551\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 732ms/step - accuracy: 0.5832 - loss: 1.1277 - val_accuracy: 0.4609 - val_loss: 1.2427\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 720ms/step - accuracy: 0.6564 - loss: 1.0580 - val_accuracy: 0.4453 - val_loss: 1.2435\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 716ms/step - accuracy: 0.6416 - loss: 1.0116 - val_accuracy: 0.4453 - val_loss: 1.2554\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 729ms/step - accuracy: 0.6106 - loss: 1.0631 - val_accuracy: 0.4531 - val_loss: 1.2470\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 726ms/step - accuracy: 0.5993 - loss: 1.0617 - val_accuracy: 0.4453 - val_loss: 1.2322\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 624ms/step - accuracy: 0.3990 - loss: 1.3025\n",
      "Validation accuracy for fold 4 of Up: 44.53%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 597ms/step\n",
      "\n",
      "Starting fold 5 for orientation Up\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 1s/step - accuracy: 0.1580 - loss: 2.0330 - val_accuracy: 0.2500 - val_loss: 1.7455\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 766ms/step - accuracy: 0.2210 - loss: 1.8230 - val_accuracy: 0.3281 - val_loss: 1.6646\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 767ms/step - accuracy: 0.2978 - loss: 1.6763 - val_accuracy: 0.3359 - val_loss: 1.6184\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 754ms/step - accuracy: 0.2868 - loss: 1.6248 - val_accuracy: 0.3672 - val_loss: 1.5885\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 749ms/step - accuracy: 0.3573 - loss: 1.5057 - val_accuracy: 0.3281 - val_loss: 1.5580\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 738ms/step - accuracy: 0.3950 - loss: 1.4995 - val_accuracy: 0.3750 - val_loss: 1.5305\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 736ms/step - accuracy: 0.4366 - loss: 1.4246 - val_accuracy: 0.3750 - val_loss: 1.5036\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 734ms/step - accuracy: 0.4528 - loss: 1.3911 - val_accuracy: 0.3750 - val_loss: 1.4892\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 729ms/step - accuracy: 0.4602 - loss: 1.3478 - val_accuracy: 0.3984 - val_loss: 1.4661\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 723ms/step - accuracy: 0.4314 - loss: 1.3900 - val_accuracy: 0.3750 - val_loss: 1.4695\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 745ms/step - accuracy: 0.4688 - loss: 1.3360 - val_accuracy: 0.3594 - val_loss: 1.4615\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 744ms/step - accuracy: 0.5120 - loss: 1.2192 - val_accuracy: 0.3516 - val_loss: 1.4482\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 732ms/step - accuracy: 0.5060 - loss: 1.2748 - val_accuracy: 0.3750 - val_loss: 1.4413\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 717ms/step - accuracy: 0.5539 - loss: 1.2139 - val_accuracy: 0.3750 - val_loss: 1.4225\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 737ms/step - accuracy: 0.5219 - loss: 1.2132 - val_accuracy: 0.3984 - val_loss: 1.4120\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 754ms/step - accuracy: 0.5486 - loss: 1.1783 - val_accuracy: 0.3594 - val_loss: 1.4146\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 761ms/step - accuracy: 0.5805 - loss: 1.1395 - val_accuracy: 0.3984 - val_loss: 1.3954\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 748ms/step - accuracy: 0.5528 - loss: 1.1526 - val_accuracy: 0.3516 - val_loss: 1.3872\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 761ms/step - accuracy: 0.5473 - loss: 1.1629 - val_accuracy: 0.3594 - val_loss: 1.3940\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 746ms/step - accuracy: 0.5675 - loss: 1.0976 - val_accuracy: 0.3672 - val_loss: 1.3763\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 759ms/step - accuracy: 0.6119 - loss: 1.0699 - val_accuracy: 0.3828 - val_loss: 1.3814\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 762ms/step - accuracy: 0.6023 - loss: 1.0834 - val_accuracy: 0.3516 - val_loss: 1.3834\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 762ms/step - accuracy: 0.6121 - loss: 1.0451 - val_accuracy: 0.3594 - val_loss: 1.3810\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 747ms/step - accuracy: 0.6261 - loss: 1.0136 - val_accuracy: 0.3672 - val_loss: 1.3700\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 750ms/step - accuracy: 0.6450 - loss: 1.0130 - val_accuracy: 0.3906 - val_loss: 1.3786\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 758ms/step - accuracy: 0.6253 - loss: 1.0075 - val_accuracy: 0.3750 - val_loss: 1.3673\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 761ms/step - accuracy: 0.6112 - loss: 1.0204 - val_accuracy: 0.3984 - val_loss: 1.3871\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 759ms/step - accuracy: 0.6244 - loss: 0.9949 - val_accuracy: 0.3906 - val_loss: 1.3526\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 770ms/step - accuracy: 0.6247 - loss: 0.9891 - val_accuracy: 0.4141 - val_loss: 1.3768\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 756ms/step - accuracy: 0.6316 - loss: 1.0057 - val_accuracy: 0.3906 - val_loss: 1.3496\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 634ms/step - accuracy: 0.4094 - loss: 1.4062\n",
      "Validation accuracy for fold 5 of Up: 39.06%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 630ms/step\n",
      "\n",
      "Average validation accuracy for Up: 40.97%\n",
      "\n",
      "Training model for orientation: Down\n",
      "\n",
      "Starting fold 1 for orientation Down\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 991ms/step - accuracy: 0.1679 - loss: 2.0624 - val_accuracy: 0.1783 - val_loss: 1.8145\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 709ms/step - accuracy: 0.1789 - loss: 1.8861 - val_accuracy: 0.2171 - val_loss: 1.7545\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 712ms/step - accuracy: 0.2494 - loss: 1.7677 - val_accuracy: 0.2868 - val_loss: 1.7205\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 712ms/step - accuracy: 0.2583 - loss: 1.7768 - val_accuracy: 0.2868 - val_loss: 1.6901\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 714ms/step - accuracy: 0.3205 - loss: 1.6614 - val_accuracy: 0.2791 - val_loss: 1.6698\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 701ms/step - accuracy: 0.3287 - loss: 1.6343 - val_accuracy: 0.3488 - val_loss: 1.6360\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 706ms/step - accuracy: 0.3167 - loss: 1.6767 - val_accuracy: 0.3566 - val_loss: 1.6051\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 728ms/step - accuracy: 0.3595 - loss: 1.6461 - val_accuracy: 0.3643 - val_loss: 1.5910\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 719ms/step - accuracy: 0.3550 - loss: 1.5667 - val_accuracy: 0.3488 - val_loss: 1.6011\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 736ms/step - accuracy: 0.3465 - loss: 1.5849 - val_accuracy: 0.3953 - val_loss: 1.5807\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 708ms/step - accuracy: 0.4151 - loss: 1.5015 - val_accuracy: 0.4186 - val_loss: 1.5703\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 682ms/step - accuracy: 0.4377 - loss: 1.5166 - val_accuracy: 0.3488 - val_loss: 1.5541\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 707ms/step - accuracy: 0.4265 - loss: 1.4833 - val_accuracy: 0.3953 - val_loss: 1.5382\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 723ms/step - accuracy: 0.3818 - loss: 1.5423 - val_accuracy: 0.3953 - val_loss: 1.5333\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 723ms/step - accuracy: 0.4278 - loss: 1.4599 - val_accuracy: 0.3798 - val_loss: 1.5236\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 702ms/step - accuracy: 0.4945 - loss: 1.3578 - val_accuracy: 0.4419 - val_loss: 1.5122\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 700ms/step - accuracy: 0.4467 - loss: 1.3908 - val_accuracy: 0.3798 - val_loss: 1.5168\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 728ms/step - accuracy: 0.4873 - loss: 1.3588 - val_accuracy: 0.4031 - val_loss: 1.5035\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 721ms/step - accuracy: 0.4347 - loss: 1.4086 - val_accuracy: 0.3953 - val_loss: 1.4928\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 715ms/step - accuracy: 0.5152 - loss: 1.3197 - val_accuracy: 0.4264 - val_loss: 1.4816\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 724ms/step - accuracy: 0.4806 - loss: 1.3416 - val_accuracy: 0.4341 - val_loss: 1.4700\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 709ms/step - accuracy: 0.4666 - loss: 1.3661 - val_accuracy: 0.4496 - val_loss: 1.4810\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 710ms/step - accuracy: 0.4749 - loss: 1.3536 - val_accuracy: 0.4419 - val_loss: 1.4712\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 719ms/step - accuracy: 0.4790 - loss: 1.3624 - val_accuracy: 0.4109 - val_loss: 1.4658\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 720ms/step - accuracy: 0.5050 - loss: 1.2981 - val_accuracy: 0.4419 - val_loss: 1.4629\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 714ms/step - accuracy: 0.4931 - loss: 1.3399 - val_accuracy: 0.4264 - val_loss: 1.4560\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 710ms/step - accuracy: 0.4817 - loss: 1.3295 - val_accuracy: 0.4341 - val_loss: 1.4590\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 715ms/step - accuracy: 0.6062 - loss: 1.2265 - val_accuracy: 0.4341 - val_loss: 1.4481\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 679ms/step - accuracy: 0.5506 - loss: 1.2561 - val_accuracy: 0.3798 - val_loss: 1.4382\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 705ms/step - accuracy: 0.5474 - loss: 1.2145 - val_accuracy: 0.4884 - val_loss: 1.4306\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 464ms/step - accuracy: 0.5096 - loss: 1.4054\n",
      "Validation accuracy for fold 1 of Down: 48.84%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 2s/step \n",
      "\n",
      "Starting fold 2 for orientation Down\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 950ms/step - accuracy: 0.1418 - loss: 2.0619 - val_accuracy: 0.1705 - val_loss: 1.8346\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 698ms/step - accuracy: 0.1539 - loss: 1.9397 - val_accuracy: 0.2403 - val_loss: 1.7593\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 707ms/step - accuracy: 0.2307 - loss: 1.8255 - val_accuracy: 0.2636 - val_loss: 1.7423\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 696ms/step - accuracy: 0.2090 - loss: 1.7674 - val_accuracy: 0.2403 - val_loss: 1.7150\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 699ms/step - accuracy: 0.2398 - loss: 1.7226 - val_accuracy: 0.2791 - val_loss: 1.6985\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 709ms/step - accuracy: 0.2993 - loss: 1.6413 - val_accuracy: 0.2636 - val_loss: 1.6886\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 699ms/step - accuracy: 0.3359 - loss: 1.6508 - val_accuracy: 0.2713 - val_loss: 1.6717\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 707ms/step - accuracy: 0.3589 - loss: 1.6061 - val_accuracy: 0.3256 - val_loss: 1.6558\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 699ms/step - accuracy: 0.3755 - loss: 1.5917 - val_accuracy: 0.3101 - val_loss: 1.6341\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 707ms/step - accuracy: 0.3134 - loss: 1.6179 - val_accuracy: 0.3256 - val_loss: 1.6176\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 698ms/step - accuracy: 0.3655 - loss: 1.5585 - val_accuracy: 0.2946 - val_loss: 1.6016\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 700ms/step - accuracy: 0.3961 - loss: 1.5501 - val_accuracy: 0.3411 - val_loss: 1.5976\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 705ms/step - accuracy: 0.3804 - loss: 1.4987 - val_accuracy: 0.3643 - val_loss: 1.5963\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 702ms/step - accuracy: 0.4146 - loss: 1.5149 - val_accuracy: 0.3101 - val_loss: 1.6013\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 723ms/step - accuracy: 0.4503 - loss: 1.4665 - val_accuracy: 0.3643 - val_loss: 1.5883\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 723ms/step - accuracy: 0.4590 - loss: 1.4495 - val_accuracy: 0.3178 - val_loss: 1.5637\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 713ms/step - accuracy: 0.4398 - loss: 1.4568 - val_accuracy: 0.3411 - val_loss: 1.5515\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 715ms/step - accuracy: 0.4519 - loss: 1.4313 - val_accuracy: 0.3566 - val_loss: 1.5557\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 721ms/step - accuracy: 0.4518 - loss: 1.4086 - val_accuracy: 0.3721 - val_loss: 1.5568\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 727ms/step - accuracy: 0.4640 - loss: 1.3896 - val_accuracy: 0.3643 - val_loss: 1.5408\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 727ms/step - accuracy: 0.4166 - loss: 1.4264 - val_accuracy: 0.3488 - val_loss: 1.5323\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 684ms/step - accuracy: 0.5092 - loss: 1.3711 - val_accuracy: 0.3488 - val_loss: 1.5369\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 685ms/step - accuracy: 0.4560 - loss: 1.3977 - val_accuracy: 0.3721 - val_loss: 1.5333\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 730ms/step - accuracy: 0.5437 - loss: 1.3105 - val_accuracy: 0.3643 - val_loss: 1.5181\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 717ms/step - accuracy: 0.5199 - loss: 1.3010 - val_accuracy: 0.3411 - val_loss: 1.5172\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 714ms/step - accuracy: 0.4506 - loss: 1.3266 - val_accuracy: 0.3953 - val_loss: 1.5029\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 706ms/step - accuracy: 0.5244 - loss: 1.3267 - val_accuracy: 0.3566 - val_loss: 1.5023\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 721ms/step - accuracy: 0.4953 - loss: 1.3144 - val_accuracy: 0.3721 - val_loss: 1.4939\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 711ms/step - accuracy: 0.5287 - loss: 1.2785 - val_accuracy: 0.3876 - val_loss: 1.4862\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 707ms/step - accuracy: 0.5442 - loss: 1.2334 - val_accuracy: 0.4341 - val_loss: 1.4841\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 456ms/step - accuracy: 0.4103 - loss: 1.5420\n",
      "Validation accuracy for fold 2 of Down: 43.41%\n",
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step \n",
      "\n",
      "Starting fold 3 for orientation Down\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 998ms/step - accuracy: 0.1656 - loss: 2.1398 - val_accuracy: 0.2188 - val_loss: 1.7904\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 705ms/step - accuracy: 0.1822 - loss: 1.8826 - val_accuracy: 0.2266 - val_loss: 1.7711\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 704ms/step - accuracy: 0.2292 - loss: 1.7954 - val_accuracy: 0.2422 - val_loss: 1.7528\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 706ms/step - accuracy: 0.3021 - loss: 1.7027 - val_accuracy: 0.2812 - val_loss: 1.7464\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 680ms/step - accuracy: 0.3118 - loss: 1.6628 - val_accuracy: 0.2812 - val_loss: 1.7388\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 674ms/step - accuracy: 0.3069 - loss: 1.5989 - val_accuracy: 0.2344 - val_loss: 1.7299\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 668ms/step - accuracy: 0.3731 - loss: 1.5837 - val_accuracy: 0.2812 - val_loss: 1.7176\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 692ms/step - accuracy: 0.3452 - loss: 1.5905 - val_accuracy: 0.3047 - val_loss: 1.7085\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 717ms/step - accuracy: 0.4223 - loss: 1.4871 - val_accuracy: 0.2891 - val_loss: 1.7122\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 714ms/step - accuracy: 0.3995 - loss: 1.4831 - val_accuracy: 0.2812 - val_loss: 1.7044\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 702ms/step - accuracy: 0.4242 - loss: 1.4498 - val_accuracy: 0.3047 - val_loss: 1.6941\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 705ms/step - accuracy: 0.4437 - loss: 1.4468 - val_accuracy: 0.2812 - val_loss: 1.6888\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 708ms/step - accuracy: 0.4344 - loss: 1.4325 - val_accuracy: 0.3125 - val_loss: 1.6844\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 714ms/step - accuracy: 0.4204 - loss: 1.4299 - val_accuracy: 0.3047 - val_loss: 1.6789\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 682ms/step - accuracy: 0.4403 - loss: 1.4368 - val_accuracy: 0.2812 - val_loss: 1.6796\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 705ms/step - accuracy: 0.4434 - loss: 1.4001 - val_accuracy: 0.2969 - val_loss: 1.6758\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 703ms/step - accuracy: 0.4930 - loss: 1.3436 - val_accuracy: 0.3125 - val_loss: 1.6655\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 713ms/step - accuracy: 0.4792 - loss: 1.3649 - val_accuracy: 0.2891 - val_loss: 1.6578\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 716ms/step - accuracy: 0.5889 - loss: 1.2676 - val_accuracy: 0.3125 - val_loss: 1.6475\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 710ms/step - accuracy: 0.5272 - loss: 1.2961 - val_accuracy: 0.3203 - val_loss: 1.6477\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 717ms/step - accuracy: 0.5048 - loss: 1.3276 - val_accuracy: 0.3281 - val_loss: 1.6460\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 722ms/step - accuracy: 0.5110 - loss: 1.2716 - val_accuracy: 0.3203 - val_loss: 1.6429\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 727ms/step - accuracy: 0.4826 - loss: 1.3069 - val_accuracy: 0.3438 - val_loss: 1.6570\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 726ms/step - accuracy: 0.5870 - loss: 1.1814 - val_accuracy: 0.3203 - val_loss: 1.6520\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 719ms/step - accuracy: 0.5749 - loss: 1.2212 - val_accuracy: 0.3359 - val_loss: 1.6437\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 733ms/step - accuracy: 0.5757 - loss: 1.1668 - val_accuracy: 0.3047 - val_loss: 1.6501\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 727ms/step - accuracy: 0.5829 - loss: 1.1844 - val_accuracy: 0.3281 - val_loss: 1.6489\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 728ms/step - accuracy: 0.5492 - loss: 1.1799 - val_accuracy: 0.2969 - val_loss: 1.6410\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 723ms/step - accuracy: 0.5662 - loss: 1.1543 - val_accuracy: 0.3438 - val_loss: 1.6320\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 730ms/step - accuracy: 0.5581 - loss: 1.1265 - val_accuracy: 0.3594 - val_loss: 1.6294\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 610ms/step - accuracy: 0.4094 - loss: 1.5694\n",
      "Validation accuracy for fold 3 of Down: 35.94%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 609ms/step\n",
      "\n",
      "Starting fold 4 for orientation Down\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 1s/step - accuracy: 0.1593 - loss: 2.0196 - val_accuracy: 0.1562 - val_loss: 1.8131\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 720ms/step - accuracy: 0.1927 - loss: 1.8666 - val_accuracy: 0.2656 - val_loss: 1.7755\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 726ms/step - accuracy: 0.2615 - loss: 1.7620 - val_accuracy: 0.2031 - val_loss: 1.7551\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 721ms/step - accuracy: 0.2427 - loss: 1.7270 - val_accuracy: 0.2969 - val_loss: 1.7233\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 722ms/step - accuracy: 0.2975 - loss: 1.6558 - val_accuracy: 0.2969 - val_loss: 1.6963\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 728ms/step - accuracy: 0.3518 - loss: 1.6124 - val_accuracy: 0.3125 - val_loss: 1.6904\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 722ms/step - accuracy: 0.3215 - loss: 1.6219 - val_accuracy: 0.2891 - val_loss: 1.6706\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 719ms/step - accuracy: 0.3988 - loss: 1.5454 - val_accuracy: 0.3047 - val_loss: 1.6543\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 698ms/step - accuracy: 0.3907 - loss: 1.5327 - val_accuracy: 0.3047 - val_loss: 1.6397\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 714ms/step - accuracy: 0.4083 - loss: 1.5016 - val_accuracy: 0.3359 - val_loss: 1.6307\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 706ms/step - accuracy: 0.4344 - loss: 1.4779 - val_accuracy: 0.3203 - val_loss: 1.6248\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 707ms/step - accuracy: 0.4321 - loss: 1.4307 - val_accuracy: 0.3359 - val_loss: 1.6104\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 708ms/step - accuracy: 0.4654 - loss: 1.4434 - val_accuracy: 0.3359 - val_loss: 1.6038\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 708ms/step - accuracy: 0.4053 - loss: 1.4988 - val_accuracy: 0.3281 - val_loss: 1.5987\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 710ms/step - accuracy: 0.4696 - loss: 1.4415 - val_accuracy: 0.3516 - val_loss: 1.5851\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 711ms/step - accuracy: 0.4901 - loss: 1.3811 - val_accuracy: 0.3438 - val_loss: 1.5898\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 698ms/step - accuracy: 0.4976 - loss: 1.3764 - val_accuracy: 0.3438 - val_loss: 1.5714\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 707ms/step - accuracy: 0.4779 - loss: 1.3177 - val_accuracy: 0.3438 - val_loss: 1.5728\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 710ms/step - accuracy: 0.5399 - loss: 1.3367 - val_accuracy: 0.3516 - val_loss: 1.5622\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 703ms/step - accuracy: 0.4960 - loss: 1.2965 - val_accuracy: 0.3672 - val_loss: 1.5575\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 710ms/step - accuracy: 0.4867 - loss: 1.3184 - val_accuracy: 0.3359 - val_loss: 1.5731\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 700ms/step - accuracy: 0.5298 - loss: 1.3081 - val_accuracy: 0.3750 - val_loss: 1.5571\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 711ms/step - accuracy: 0.5115 - loss: 1.2451 - val_accuracy: 0.3203 - val_loss: 1.5384\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 707ms/step - accuracy: 0.5374 - loss: 1.2540 - val_accuracy: 0.3594 - val_loss: 1.5287\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 700ms/step - accuracy: 0.5677 - loss: 1.2037 - val_accuracy: 0.3828 - val_loss: 1.5169\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 700ms/step - accuracy: 0.5401 - loss: 1.2213 - val_accuracy: 0.3594 - val_loss: 1.5150\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 718ms/step - accuracy: 0.5588 - loss: 1.1729 - val_accuracy: 0.3672 - val_loss: 1.5054\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 718ms/step - accuracy: 0.5692 - loss: 1.1617 - val_accuracy: 0.3828 - val_loss: 1.4995\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 726ms/step - accuracy: 0.5831 - loss: 1.1526 - val_accuracy: 0.3672 - val_loss: 1.5014\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 721ms/step - accuracy: 0.6342 - loss: 1.1206 - val_accuracy: 0.3672 - val_loss: 1.5092\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 597ms/step - accuracy: 0.3562 - loss: 1.5549\n",
      "Validation accuracy for fold 4 of Down: 36.72%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 603ms/step\n",
      "\n",
      "Starting fold 5 for orientation Down\n",
      "Epoch 1/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 998ms/step - accuracy: 0.1356 - loss: 2.2896 - val_accuracy: 0.1875 - val_loss: 1.8018\n",
      "Epoch 2/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 731ms/step - accuracy: 0.1697 - loss: 1.8916 - val_accuracy: 0.2500 - val_loss: 1.7627\n",
      "Epoch 3/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 727ms/step - accuracy: 0.1939 - loss: 1.8285 - val_accuracy: 0.3047 - val_loss: 1.7249\n",
      "Epoch 4/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 735ms/step - accuracy: 0.2523 - loss: 1.7368 - val_accuracy: 0.3047 - val_loss: 1.7014\n",
      "Epoch 5/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 725ms/step - accuracy: 0.2450 - loss: 1.6934 - val_accuracy: 0.3125 - val_loss: 1.6822\n",
      "Epoch 6/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 710ms/step - accuracy: 0.3179 - loss: 1.6469 - val_accuracy: 0.3672 - val_loss: 1.6638\n",
      "Epoch 7/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 695ms/step - accuracy: 0.3026 - loss: 1.6629 - val_accuracy: 0.3594 - val_loss: 1.6519\n",
      "Epoch 8/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 729ms/step - accuracy: 0.3600 - loss: 1.5726 - val_accuracy: 0.3984 - val_loss: 1.6394\n",
      "Epoch 9/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 726ms/step - accuracy: 0.3598 - loss: 1.5608 - val_accuracy: 0.3281 - val_loss: 1.6214\n",
      "Epoch 10/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 737ms/step - accuracy: 0.3763 - loss: 1.5581 - val_accuracy: 0.3359 - val_loss: 1.6004\n",
      "Epoch 11/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 733ms/step - accuracy: 0.4084 - loss: 1.5203 - val_accuracy: 0.3672 - val_loss: 1.5865\n",
      "Epoch 12/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 720ms/step - accuracy: 0.3752 - loss: 1.5218 - val_accuracy: 0.3906 - val_loss: 1.5806\n",
      "Epoch 13/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 724ms/step - accuracy: 0.3982 - loss: 1.4974 - val_accuracy: 0.3828 - val_loss: 1.5747\n",
      "Epoch 14/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 716ms/step - accuracy: 0.4615 - loss: 1.4673 - val_accuracy: 0.4062 - val_loss: 1.5627\n",
      "Epoch 15/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 715ms/step - accuracy: 0.4412 - loss: 1.4479 - val_accuracy: 0.4062 - val_loss: 1.5504\n",
      "Epoch 16/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 712ms/step - accuracy: 0.4428 - loss: 1.4212 - val_accuracy: 0.4062 - val_loss: 1.5379\n",
      "Epoch 17/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 678ms/step - accuracy: 0.5021 - loss: 1.3937 - val_accuracy: 0.3828 - val_loss: 1.5340\n",
      "Epoch 18/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 682ms/step - accuracy: 0.4705 - loss: 1.3558 - val_accuracy: 0.4453 - val_loss: 1.5230\n",
      "Epoch 19/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 676ms/step - accuracy: 0.4759 - loss: 1.3444 - val_accuracy: 0.4219 - val_loss: 1.5114\n",
      "Epoch 20/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 694ms/step - accuracy: 0.4822 - loss: 1.3205 - val_accuracy: 0.4219 - val_loss: 1.5002\n",
      "Epoch 21/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 699ms/step - accuracy: 0.4971 - loss: 1.3276 - val_accuracy: 0.4141 - val_loss: 1.4991\n",
      "Epoch 22/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 680ms/step - accuracy: 0.5204 - loss: 1.3073 - val_accuracy: 0.4141 - val_loss: 1.4969\n",
      "Epoch 23/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 682ms/step - accuracy: 0.5284 - loss: 1.3056 - val_accuracy: 0.3984 - val_loss: 1.4981\n",
      "Epoch 24/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 664ms/step - accuracy: 0.5016 - loss: 1.2791 - val_accuracy: 0.3906 - val_loss: 1.4866\n",
      "Epoch 25/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 682ms/step - accuracy: 0.5054 - loss: 1.2636 - val_accuracy: 0.4453 - val_loss: 1.4768\n",
      "Epoch 26/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 685ms/step - accuracy: 0.5333 - loss: 1.2546 - val_accuracy: 0.4531 - val_loss: 1.4832\n",
      "Epoch 27/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 688ms/step - accuracy: 0.5473 - loss: 1.2490 - val_accuracy: 0.4062 - val_loss: 1.4846\n",
      "Epoch 28/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 682ms/step - accuracy: 0.5526 - loss: 1.2115 - val_accuracy: 0.4219 - val_loss: 1.4750\n",
      "Epoch 29/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 683ms/step - accuracy: 0.5351 - loss: 1.2293 - val_accuracy: 0.4219 - val_loss: 1.4691\n",
      "Epoch 30/30\n",
      "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 688ms/step - accuracy: 0.5267 - loss: 1.2204 - val_accuracy: 0.4297 - val_loss: 1.4585\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 576ms/step - accuracy: 0.3865 - loss: 1.4774\n",
      "Validation accuracy for fold 5 of Down: 42.97%\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 573ms/step\n",
      "\n",
      "Average validation accuracy for Down: 41.57%\n",
      "Training and evaluation complete for all orientations.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Emotion labels for reference\n",
    "emotion_labels = ['NE', 'SA', 'SM', 'SO', 'SU', 'YN']\n",
    "\n",
    "# Train and evaluate model for each orientation with cross-validation\n",
    "results = {}\n",
    "\n",
    "# Number of epochs and learning rate\n",
    "epochs = 30\n",
    "learning_rate = 0.0001\n",
    "\n",
    "for ori_name, (data, labels) in orientation_data.items():\n",
    "    print(f\"\\nTraining model for orientation: {ori_name}\")\n",
    "    \n",
    "    # Reshape data and convert labels to one-hot encoding\n",
    "    data = data.reshape(-1, 224, 224, 3)\n",
    "    labels_one_hot = to_categorical(labels, num_classes=len(emotion_labels))\n",
    "    \n",
    "    # Stratified K-Fold Cross-Validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    orientation_accuracies = []\n",
    "    orientation_reports = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(data, labels)):\n",
    "        print(f\"\\nStarting fold {fold + 1} for orientation {ori_name}\")\n",
    "        \n",
    "        # Split data into training and validation sets for the fold\n",
    "        X_train, X_val = data[train_idx], data[val_idx]\n",
    "        y_train, y_val = labels_one_hot[train_idx], labels_one_hot[val_idx]\n",
    "        \n",
    "        # Initialize the InceptionV3 model with pretrained weights\n",
    "        base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "        # Set the base model layers to non-trainable\n",
    "        base_model.trainable = False\n",
    "\n",
    "        # Add custom layers on top\n",
    "        x = GlobalAveragePooling2D()(base_model.output)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.5)(x)  # Add dropout for regularization\n",
    "        output = Dense(len(emotion_labels), activation='softmax')(x)\n",
    "        model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "        # Compile the model\n",
    "        model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        # Train the model without callbacks\n",
    "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=32, validation_data=(X_val, y_val), verbose=1)\n",
    "\n",
    "        # Evaluate the model on the validation set\n",
    "        val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=1)\n",
    "        print(f\"Validation accuracy for fold {fold + 1} of {ori_name}: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "        # Generate a classification report for the fold\n",
    "        y_pred = model.predict(X_val)\n",
    "        y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "        y_val_classes = np.argmax(y_val, axis=1)\n",
    "        report = classification_report(y_val_classes, y_pred_classes, target_names=emotion_labels, output_dict=True)\n",
    "        \n",
    "        # Store accuracy and report for each fold\n",
    "        orientation_accuracies.append(val_accuracy)\n",
    "        orientation_reports.append(report)\n",
    "\n",
    "    # Store results for each orientation\n",
    "    avg_accuracy = np.mean(orientation_accuracies)\n",
    "    results[ori_name] = {\n",
    "        'avg_accuracy': avg_accuracy,\n",
    "        'classification_reports': orientation_reports\n",
    "    }\n",
    "\n",
    "    print(f\"\\nAverage validation accuracy for {ori_name}: {avg_accuracy * 100:.2f}%\")\n",
    "\n",
    "print(\"Training and evaluation complete for all orientations.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e9d6285-600e-4e40-94f8-43de3f38a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVM model with cross-validation for orientation: Front\n",
      "Best parameters for Front orientation: {'svc__C': 100, 'svc__gamma': 0.001, 'svc__kernel': 'linear'}\n",
      "Cross-validated Accuracy for Front orientation: 56.59%\n",
      "\n",
      "Training SVM model with cross-validation for orientation: Up\n",
      "Best parameters for Up orientation: {'svc__C': 100, 'svc__gamma': 0.001, 'svc__kernel': 'linear'}\n",
      "Cross-validated Accuracy for Up orientation: 48.84%\n",
      "\n",
      "Training SVM model with cross-validation for orientation: Down\n",
      "Best parameters for Down orientation: {'svc__C': 100, 'svc__gamma': 0.001, 'svc__kernel': 'linear'}\n",
      "Cross-validated Accuracy for Down orientation: 44.19%\n",
      "\n",
      "Summary of SVM Model Accuracies with Cross-Validation:\n",
      "Orientation Front: 56.59%\n",
      "Orientation Up: 48.84%\n",
      "Orientation Down: 44.19%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Set up an empty dictionary to store models and results for each orientation\n",
    "orientation_models = {}\n",
    "orientation_accuracies = {}\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'svc__C': [100],        # Fixed C value as specified\n",
    "    'svc__gamma': [0.001],  # Fixed gamma value as specified\n",
    "    'svc__kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Train and evaluate an SVM for each orientation with cross-validation\n",
    "for orientation, (X, y) in orientation_data.items():\n",
    "    print(f\"\\nTraining SVM model with cross-validation for orientation: {orientation}\")\n",
    "\n",
    "    # Flatten images for SVM input\n",
    "    X_flat = X.reshape(X.shape[0], -1)  # Reshape to (num_samples, num_features)\n",
    "\n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_flat, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Create a pipeline with StandardScaler and SVM\n",
    "    pipeline = make_pipeline(StandardScaler(), SVC())\n",
    "\n",
    "    # Grid search with 5-fold cross-validation\n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Best model and parameters\n",
    "    best_model = grid_search.best_estimator_\n",
    "    orientation_models[orientation] = best_model\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    orientation_accuracies[orientation] = accuracy\n",
    "\n",
    "    print(f\"Best parameters for {orientation} orientation: {grid_search.best_params_}\")\n",
    "    print(f\"Cross-validated Accuracy for {orientation} orientation: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display accuracies for each orientation\n",
    "print(\"\\nSummary of SVM Model Accuracies with Cross-Validation:\")\n",
    "for orientation, accuracy in orientation_accuracies.items():\n",
    "    print(f\"Orientation {orientation}: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "594ce892-6470-4fe5-8b69-f3b6bfba1301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing orientation: Front\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 246ms/step\n",
      "Best parameters for Front: {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Cross-validated Accuracy for Front: 58.14%\n",
      "\n",
      "Processing orientation: Up\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step\n",
      "Best parameters for Up: {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Cross-validated Accuracy for Up: 52.71%\n",
      "\n",
      "Processing orientation: Down\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step\n",
      "Best parameters for Down: {'C': 100, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Cross-validated Accuracy for Down: 43.41%\n",
      "\n",
      "Summary of SVM Model Accuracies with InceptionV3 Features:\n",
      "Orientation Front: 58.14%\n",
      "Orientation Up: 52.71%\n",
      "Orientation Down: 43.41%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load InceptionV3 model without the top layer\n",
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "feature_extractor = Model(inputs=inception_model.input, outputs=inception_model.output)\n",
    "\n",
    "# Set up dictionaries to store models and accuracies for each orientation\n",
    "orientation_models = {}\n",
    "orientation_accuracies = {}\n",
    "\n",
    "# Define SVM parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [100],       # Set C value as specified\n",
    "    'gamma': [0.001], # Set gamma value as specified\n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Loop through each orientation, extract features, train SVM, and evaluate\n",
    "for orientation, (X, y) in orientation_data.items():\n",
    "    print(f\"\\nProcessing orientation: {orientation}\")\n",
    "\n",
    "    # Apply InceptionV3 preprocessing to each image\n",
    "    X_preprocessed = preprocess_input(X)\n",
    "\n",
    "    # Extract features with InceptionV3\n",
    "    X_features = feature_extractor.predict(X_preprocessed)\n",
    "    X_features_flat = X_features.reshape(X_features.shape[0], -1)  # Flatten features for SVM input\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features_flat, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Train SVM with cross-validation using GridSearchCV\n",
    "    svm = SVC()\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Save the best model and evaluate it\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    orientation_models[orientation] = best_svm\n",
    "    y_pred = best_svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    orientation_accuracies[orientation] = accuracy\n",
    "\n",
    "    # Output results for this orientation\n",
    "    print(f\"Best parameters for {orientation}: {grid_search.best_params_}\")\n",
    "    print(f\"Cross-validated Accuracy for {orientation}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display summary of accuracies\n",
    "print(\"\\nSummary of SVM Model Accuracies with InceptionV3 Features:\")\n",
    "for orientation, accuracy in orientation_accuracies.items():\n",
    "    print(f\"Orientation {orientation}: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a891871-3fe4-4cc2-b8de-666bc8345c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing orientation: Front\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 254ms/step\n",
      "Best parameters for Front: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Cross-validated Accuracy for Front: 45.74%\n",
      "\n",
      "Processing orientation: Up\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step\n",
      "Best parameters for Up: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Cross-validated Accuracy for Up: 43.41%\n",
      "\n",
      "Processing orientation: Down\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 194ms/step\n",
      "Best parameters for Down: {'C': 10, 'gamma': 0.001, 'kernel': 'linear'}\n",
      "Cross-validated Accuracy for Down: 29.46%\n",
      "\n",
      "Summary of SVM Model Accuracies with InceptionV3 Features:\n",
      "Orientation Front: 45.74%\n",
      "Orientation Up: 43.41%\n",
      "Orientation Down: 29.46%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load InceptionV3 model without the top layer\n",
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "feature_extractor = Model(inputs=inception_model.input, outputs=inception_model.output)\n",
    "\n",
    "# Set up dictionaries to store models and accuracies for each orientation\n",
    "orientation_models = {}\n",
    "orientation_accuracies = {}\n",
    "\n",
    "# Define SVM parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [10],       # Set C value as specified\n",
    "    'gamma': [0.001], # Set gamma value as specified\n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Loop through each orientation, extract features, train SVM, and evaluate\n",
    "for orientation, (X, y) in orientation_data.items():\n",
    "    print(f\"\\nProcessing orientation: {orientation}\")\n",
    "\n",
    "    # Apply InceptionV3 preprocessing to each image\n",
    "    X_preprocessed = preprocess_input(X)\n",
    "\n",
    "    # Extract features with InceptionV3\n",
    "    X_features = feature_extractor.predict(X_preprocessed)\n",
    "    X_features_flat = X_features.reshape(X_features.shape[0], -1)  # Flatten features for SVM input\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features_flat, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Train SVM with cross-validation using GridSearchCV\n",
    "    svm = SVC()\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Save the best model and evaluate it\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    orientation_models[orientation] = best_svm\n",
    "    y_pred = best_svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    orientation_accuracies[orientation] = accuracy\n",
    "\n",
    "    # Output results for this orientation\n",
    "    print(f\"Best parameters for {orientation}: {grid_search.best_params_}\")\n",
    "    print(f\"Cross-validated Accuracy for {orientation}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display summary of accuracies\n",
    "print(\"\\nSummary of SVM Model Accuracies with InceptionV3 Features:\")\n",
    "for orientation, accuracy in orientation_accuracies.items():\n",
    "    print(f\"Orientation {orientation}: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bf1fc15-4d16-4e56-9f44-fa0c4367c514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing orientation: Front\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 269ms/step\n",
      "Best parameters for Front: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Cross-validated Accuracy for Front: 58.91%\n",
      "\n",
      "Processing orientation: Up\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 194ms/step\n",
      "Best parameters for Up: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Cross-validated Accuracy for Up: 39.53%\n",
      "\n",
      "Processing orientation: Down\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 190ms/step\n",
      "Best parameters for Down: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Cross-validated Accuracy for Down: 27.13%\n",
      "\n",
      "Summary of Random Forest Model Accuracies with InceptionV3 Features:\n",
      "Orientation Front: 58.91%\n",
      "Orientation Up: 39.53%\n",
      "Orientation Down: 27.13%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load InceptionV3 model without the top layer\n",
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "feature_extractor = Model(inputs=inception_model.input, outputs=inception_model.output)\n",
    "\n",
    "# Set up dictionaries to store models and accuracies for each orientation\n",
    "orientation_models = {}\n",
    "orientation_accuracies = {}\n",
    "\n",
    "# Define Random Forest parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100],  # Adjust values as needed\n",
    "    'max_depth': [10],  # Try different depths for better results\n",
    "    'min_samples_split': [2]  # Split sizes for improved generalization\n",
    "}\n",
    "\n",
    "# Loop through each orientation, extract features, train Random Forest, and evaluate\n",
    "for orientation, (X, y) in orientation_data.items():\n",
    "    print(f\"\\nProcessing orientation: {orientation}\")\n",
    "\n",
    "    # Apply InceptionV3 preprocessing to each image\n",
    "    X_preprocessed = preprocess_input(X)\n",
    "\n",
    "    # Extract features with InceptionV3\n",
    "    X_features = feature_extractor.predict(X_preprocessed)\n",
    "    X_features_flat = X_features.reshape(X_features.shape[0], -1)  # Flatten features for Random Forest input\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features_flat, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Train Random Forest with cross-validation using GridSearchCV\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Save the best model and evaluate it\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    orientation_models[orientation] = best_rf\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    orientation_accuracies[orientation] = accuracy\n",
    "\n",
    "    # Output results for this orientation\n",
    "    print(f\"Best parameters for {orientation}: {grid_search.best_params_}\")\n",
    "    print(f\"Cross-validated Accuracy for {orientation}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display summary of accuracies\n",
    "print(\"\\nSummary of Random Forest Model Accuracies with InceptionV3 Features:\")\n",
    "for orientation, accuracy in orientation_accuracies.items():\n",
    "    print(f\"Orientation {orientation}: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79904edb-3610-463e-8c1f-de0880699b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing orientation: Front\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 255ms/step\n",
      "Best parameters for Front: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Cross-validated Accuracy for Front: 16.28%\n",
      "\n",
      "Processing orientation: Up\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 191ms/step\n",
      "Best parameters for Up: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Cross-validated Accuracy for Up: 16.28%\n",
      "\n",
      "Processing orientation: Down\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 186ms/step\n",
      "Best parameters for Down: {'max_depth': 10, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Cross-validated Accuracy for Down: 16.28%\n",
      "\n",
      "Summary of Random Forest Model Accuracies with InceptionV3 Features:\n",
      "Orientation Front: 16.28%\n",
      "Orientation Up: 16.28%\n",
      "Orientation Down: 16.28%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load InceptionV3 model without the top layer\n",
    "inception_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "feature_extractor = Model(inputs=inception_model.input, outputs=inception_model.output)\n",
    "\n",
    "# Set up dictionaries to store models and accuracies for each orientation\n",
    "orientation_models = {}\n",
    "orientation_accuracies = {}\n",
    "\n",
    "# Define Random Forest parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],  # Adjust values as needed\n",
    "    'max_depth': [10, 20],  # Try different depths for better results\n",
    "    'min_samples_split': [2, 5, 10]  # Split sizes for improved generalization\n",
    "}\n",
    "\n",
    "# Loop through each orientation, extract features, train Random Forest, and evaluate\n",
    "for orientation, (X, y) in orientation_data.items():\n",
    "    print(f\"\\nProcessing orientation: {orientation}\")\n",
    "\n",
    "    # Apply InceptionV3 preprocessing to each image\n",
    "    X_preprocessed = preprocess_input(X)\n",
    "\n",
    "    # Extract features with InceptionV3\n",
    "    X_features = feature_extractor.predict(X_preprocessed)\n",
    "    X_features_flat = X_features.reshape(X_features.shape[0], -1)  # Flatten features for Random Forest input\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features_flat, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Train Random Forest with cross-validation using GridSearchCV\n",
    "    rf = RandomForestClassifier(random_state=42)\n",
    "    grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Save the best model and evaluate it\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    orientation_models[orientation] = best_rf\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    orientation_accuracies[orientation] = accuracy\n",
    "\n",
    "    # Output results for this orientation\n",
    "    print(f\"Best parameters for {orientation}: {grid_search.best_params_}\")\n",
    "    print(f\"Cross-validated Accuracy for {orientation}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display summary of accuracies\n",
    "print(\"\\nSummary of Random Forest Model Accuracies with InceptionV3 Features:\")\n",
    "for orientation, accuracy in orientation_accuracies.items():\n",
    "    print(f\"Orientation {orientation}: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9d1a5ce-1926-493f-80b1-6b40b15c51fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing orientation: Front\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 189ms/step\n",
      "Best parameters for Front: {'C': 100, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Cross-validated Accuracy for Front: 57.36%\n",
      "\n",
      "Processing orientation: Up\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 126ms/step\n",
      "Best parameters for Up: {'C': 100, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Cross-validated Accuracy for Up: 49.61%\n",
      "\n",
      "Processing orientation: Down\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 122ms/step\n",
      "Best parameters for Down: {'C': 100, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Cross-validated Accuracy for Down: 48.06%\n",
      "\n",
      "Summary of SVM Model Accuracies with MobileNetV2 Features:\n",
      "Orientation Front: 57.36%\n",
      "Orientation Up: 49.61%\n",
      "Orientation Down: 48.06%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load MobileNetV2 model without the top layer\n",
    "mobilenet_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "feature_extractor = Model(inputs=mobilenet_model.input, outputs=mobilenet_model.output)\n",
    "\n",
    "# Set up dictionaries to store models and accuracies for each orientation\n",
    "orientation_models = {}\n",
    "orientation_accuracies = {}\n",
    "\n",
    "# Define SVM parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [100],       # Example values to try; adjust based on your results\n",
    "    'gamma': [0.1], # Example gamma values\n",
    "    'kernel': ['linear']\n",
    "}\n",
    "\n",
    "# Loop through each orientation, extract features, train SVM, and evaluate\n",
    "for orientation, (X, y) in orientation_data.items():\n",
    "    print(f\"\\nProcessing orientation: {orientation}\")\n",
    "\n",
    "    # Apply MobileNetV2 preprocessing to each image\n",
    "    X_preprocessed = preprocess_input(X)\n",
    "\n",
    "    # Extract features with MobileNetV2\n",
    "    X_features = feature_extractor.predict(X_preprocessed)\n",
    "    X_features_flat = X_features.reshape(X_features.shape[0], -1)  # Flatten features for SVM input\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features_flat, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Train SVM with cross-validation using GridSearchCV\n",
    "    svm = SVC()\n",
    "    grid_search = GridSearchCV(svm, param_grid, cv=5, scoring='accuracy')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Save the best model and evaluate it\n",
    "    best_svm = grid_search.best_estimator_\n",
    "    orientation_models[orientation] = best_svm\n",
    "    y_pred = best_svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    orientation_accuracies[orientation] = accuracy\n",
    "\n",
    "    # Output results for this orientation\n",
    "    print(f\"Best parameters for {orientation}: {grid_search.best_params_}\")\n",
    "    print(f\"Cross-validated Accuracy for {orientation}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display summary of accuracies\n",
    "print(\"\\nSummary of SVM Model Accuracies with MobileNetV2 Features:\")\n",
    "for orientation, accuracy in orientation_accuracies.items():\n",
    "    print(f\"Orientation {orientation}: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcad84da-eb24-4dd6-b6f7-7fa3449944c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing orientation: Front\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 191ms/step\n",
      "Accuracy for Front with specified Random Forest parameters: 45.74%\n",
      "\n",
      "Processing orientation: Up\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 128ms/step\n",
      "Accuracy for Up with specified Random Forest parameters: 34.88%\n",
      "\n",
      "Processing orientation: Down\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 124ms/step\n",
      "Accuracy for Down with specified Random Forest parameters: 27.13%\n",
      "\n",
      "Summary of Random Forest Model Accuracies with MobileNetV2 Features:\n",
      "Orientation Front: 45.74%\n",
      "Orientation Up: 34.88%\n",
      "Orientation Down: 27.13%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load MobileNetV2 model without the top layer\n",
    "mobilenet_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "feature_extractor = Model(inputs=mobilenet_model.input, outputs=mobilenet_model.output)\n",
    "\n",
    "# Set up dictionaries to store models and accuracies for each orientation\n",
    "orientation_models = {}\n",
    "orientation_accuracies = {}\n",
    "\n",
    "# Define a single set of hyperparameters for Random Forest\n",
    "rf_params = {\n",
    "    'n_estimators': 100,      # Number of trees in the forest\n",
    "    'max_depth': 20,          # Maximum depth of the tree\n",
    "    'min_samples_split': 5    # Minimum number of samples required to split an internal node\n",
    "}\n",
    "\n",
    "# Loop through each orientation, extract features, train Random Forest, and evaluate\n",
    "for orientation, (X, y) in orientation_data.items():\n",
    "    print(f\"\\nProcessing orientation: {orientation}\")\n",
    "\n",
    "    # Apply MobileNetV2 preprocessing to each image\n",
    "    X_preprocessed = preprocess_input(X)\n",
    "\n",
    "    # Extract features with MobileNetV2\n",
    "    X_features = feature_extractor.predict(X_preprocessed)\n",
    "    X_features_flat = X_features.reshape(X_features.shape[0], -1)  # Flatten features for Random Forest input\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features_flat, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Train Random Forest using the fixed set of hyperparameters\n",
    "    rf = RandomForestClassifier(**rf_params, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Save the model and evaluate it\n",
    "    orientation_models[orientation] = rf\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    orientation_accuracies[orientation] = accuracy\n",
    "\n",
    "    # Output results for this orientation\n",
    "    print(f\"Accuracy for {orientation} with specified Random Forest parameters: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display summary of accuracies\n",
    "print(\"\\nSummary of Random Forest Model Accuracies with MobileNetV2 Features:\")\n",
    "for orientation, accuracy in orientation_accuracies.items():\n",
    "    print(f\"Orientation {orientation}: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c8e3f4-a96a-481a-a686-e4377780ddce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing orientation: Front\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 294ms/step\n",
      "Accuracy for Front with EfficientNet and SVM: 24.03%\n",
      "\n",
      "Processing orientation: Up\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 184ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load EfficientNetB0 model without the top layer\n",
    "efficientnet_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "feature_extractor = Model(inputs=efficientnet_model.input, outputs=efficientnet_model.output)\n",
    "\n",
    "# Set up dictionaries to store models and accuracies for each orientation\n",
    "orientation_models = {}\n",
    "orientation_accuracies = {}\n",
    "\n",
    "# Define a single set of hyperparameters for SVM\n",
    "svm_params = {\n",
    "    'C': 100,       # Regularization parameter\n",
    "    'gamma': 0.001, # Kernel coefficient\n",
    "    'kernel': 'linear'\n",
    "}\n",
    "\n",
    "# Loop through each orientation, extract features, train SVM, and evaluate\n",
    "for orientation, (X, y) in orientation_data.items():\n",
    "    print(f\"\\nProcessing orientation: {orientation}\")\n",
    "\n",
    "    # Apply EfficientNet preprocessing to each image\n",
    "    X_preprocessed = preprocess_input(X)\n",
    "\n",
    "    # Extract features with EfficientNetB0\n",
    "    X_features = feature_extractor.predict(X_preprocessed)\n",
    "    X_features_flat = X_features.reshape(X_features.shape[0], -1)  # Flatten features for SVM input\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features_flat, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Train SVM using the specified hyperparameters\n",
    "    svm = SVC(**svm_params)\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    # Save the model and evaluate it\n",
    "    orientation_models[orientation] = svm\n",
    "    y_pred = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    orientation_accuracies[orientation] = accuracy\n",
    "\n",
    "    # Output results for this orientation\n",
    "    print(f\"Accuracy for {orientation} with EfficientNet and SVM: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display summary of accuracies\n",
    "print(\"\\nSummary of SVM Model Accuracies with EfficientNet Features:\")\n",
    "for orientation, accuracy in orientation_accuracies.items():\n",
    "    print(f\"Orientation {orientation}: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73a0066a-7f28-4413-aa37-be874dfa13b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing orientation: Front\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 218ms/step\n",
      "Accuracy for Front with EfficientNet and RandomForest: 44.96%\n",
      "\n",
      "Processing orientation: Up\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 154ms/step\n",
      "Accuracy for Up with EfficientNet and RandomForest: 42.64%\n",
      "\n",
      "Processing orientation: Down\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 158ms/step\n",
      "Accuracy for Down with EfficientNet and RandomForest: 26.36%\n",
      "\n",
      "Summary of RandomForest Model Accuracies with EfficientNet Features:\n",
      "Orientation Front: 44.96%\n",
      "Orientation Up: 42.64%\n",
      "Orientation Down: 26.36%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load EfficientNetB0 model without the top layer\n",
    "efficientnet_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "feature_extractor = Model(inputs=efficientnet_model.input, outputs=efficientnet_model.output)\n",
    "\n",
    "# Set up dictionaries to store models and accuracies for each orientation\n",
    "orientation_models = {}\n",
    "orientation_accuracies = {}\n",
    "\n",
    "# Define RandomForest parameters (You can modify them for hyperparameter tuning)\n",
    "rf_params = {\n",
    "    'n_estimators': 100,    # Number of trees in the forest\n",
    "    'max_depth': 10,         # Max depth of the tree\n",
    "    'random_state': 42       # Ensuring reproducibility\n",
    "}\n",
    "\n",
    "# Loop through each orientation, extract features, train RandomForest, and evaluate\n",
    "for orientation, (X, y) in orientation_data.items():\n",
    "    print(f\"\\nProcessing orientation: {orientation}\")\n",
    "\n",
    "    # Apply EfficientNet preprocessing to each image\n",
    "    X_preprocessed = preprocess_input(X)\n",
    "\n",
    "    # Extract features with EfficientNetB0\n",
    "    X_features = feature_extractor.predict(X_preprocessed)\n",
    "    X_features_flat = X_features.reshape(X_features.shape[0], -1)  # Flatten features for RandomForest input\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features_flat, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Train RandomForest with the specified hyperparameters\n",
    "    rf = RandomForestClassifier(**rf_params)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Save the model and evaluate it\n",
    "    orientation_models[orientation] = rf\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    orientation_accuracies[orientation] = accuracy\n",
    "\n",
    "    # Output results for this orientation\n",
    "    print(f\"Accuracy for {orientation} with EfficientNet and RandomForest: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display summary of accuracies\n",
    "print(\"\\nSummary of RandomForest Model Accuracies with EfficientNet Features:\")\n",
    "for orientation, accuracy in orientation_accuracies.items():\n",
    "    print(f\"Orientation {orientation}: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9f98d70-92a0-430d-895a-132301a03b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing orientation: Front\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 393ms/step\n",
      "Accuracy for Front with ResNet50 and SVM: 59.69%\n",
      "\n",
      "Processing orientation: Up\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 353ms/step\n",
      "Accuracy for Up with ResNet50 and SVM: 51.94%\n",
      "\n",
      "Processing orientation: Down\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 370ms/step\n",
      "Accuracy for Down with ResNet50 and SVM: 45.74%\n",
      "\n",
      "Summary of SVM Model Accuracies with ResNet50 Features:\n",
      "Orientation Front: 59.69%\n",
      "Orientation Up: 51.94%\n",
      "Orientation Down: 45.74%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load ResNet50 model without the top layer\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "feature_extractor = Model(inputs=resnet_model.input, outputs=resnet_model.output)\n",
    "\n",
    "# Set up dictionaries to store models and accuracies for each orientation\n",
    "orientation_models = {}\n",
    "orientation_accuracies = {}\n",
    "\n",
    "# Define SVM parameters (You can modify them for hyperparameter tuning)\n",
    "svm_params = {\n",
    "    'C': 100,       # Regularization parameter\n",
    "    'gamma': 0.001, # Kernel coefficient\n",
    "    'kernel': 'linear'\n",
    "}\n",
    "\n",
    "# Loop through each orientation, extract features, train SVM, and evaluate\n",
    "for orientation, (X, y) in orientation_data.items():\n",
    "    print(f\"\\nProcessing orientation: {orientation}\")\n",
    "\n",
    "    # Apply ResNet50 preprocessing to each image\n",
    "    X_preprocessed = preprocess_input(X)\n",
    "\n",
    "    # Extract features with ResNet50\n",
    "    X_features = feature_extractor.predict(X_preprocessed)\n",
    "    X_features_flat = X_features.reshape(X_features.shape[0], -1)  # Flatten features for SVM input\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features_flat, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Train SVM with the specified hyperparameters\n",
    "    svm = SVC(**svm_params)\n",
    "    svm.fit(X_train, y_train)\n",
    "\n",
    "    # Save the model and evaluate it\n",
    "    orientation_models[orientation] = svm\n",
    "    y_pred = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    orientation_accuracies[orientation] = accuracy\n",
    "\n",
    "    # Output results for this orientation\n",
    "    print(f\"Accuracy for {orientation} with ResNet50 and SVM: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display summary of accuracies\n",
    "print(\"\\nSummary of SVM Model Accuracies with ResNet50 Features:\")\n",
    "for orientation, accuracy in orientation_accuracies.items():\n",
    "    print(f\"Orientation {orientation}: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38810b67-ee66-4d62-a071-b2cff9d27e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing orientation: Front\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 431ms/step\n",
      "Accuracy for Front with ResNet50 and RandomForest: 47.29%\n",
      "\n",
      "Processing orientation: Up\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 379ms/step\n",
      "Accuracy for Up with ResNet50 and RandomForest: 37.21%\n",
      "\n",
      "Processing orientation: Down\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 378ms/step\n",
      "Accuracy for Down with ResNet50 and RandomForest: 22.48%\n",
      "\n",
      "Summary of RandomForest Model Accuracies with ResNet50 Features:\n",
      "Orientation Front: 47.29%\n",
      "Orientation Up: 37.21%\n",
      "Orientation Down: 22.48%\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load ResNet50 model without the top layer\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "feature_extractor = Model(inputs=resnet_model.input, outputs=resnet_model.output)\n",
    "\n",
    "# Set up dictionaries to store models and accuracies for each orientation\n",
    "orientation_models = {}\n",
    "orientation_accuracies = {}\n",
    "\n",
    "# Define RandomForest parameters (You can modify them for hyperparameter tuning)\n",
    "rf_params = {\n",
    "    'n_estimators': 100,    # Number of trees in the forest\n",
    "    'max_depth': 10,        # Maximum depth of the trees\n",
    "    'random_state': 42      # Set random state for reproducibility\n",
    "}\n",
    "\n",
    "# Loop through each orientation, extract features, train RandomForest, and evaluate\n",
    "for orientation, (X, y) in orientation_data.items():\n",
    "    print(f\"\\nProcessing orientation: {orientation}\")\n",
    "\n",
    "    # Apply ResNet50 preprocessing to each image\n",
    "    X_preprocessed = preprocess_input(X)\n",
    "\n",
    "    # Extract features with ResNet50\n",
    "    X_features = feature_extractor.predict(X_preprocessed)\n",
    "    X_features_flat = X_features.reshape(X_features.shape[0], -1)  # Flatten features for RandomForest input\n",
    "\n",
    "    # Split data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_features_flat, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "    # Train RandomForest with the specified hyperparameters\n",
    "    rf = RandomForestClassifier(**rf_params)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Save the model and evaluate it\n",
    "    orientation_models[orientation] = rf\n",
    "    y_pred = rf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    orientation_accuracies[orientation] = accuracy\n",
    "\n",
    "    # Output results for this orientation\n",
    "    print(f\"Accuracy for {orientation} with ResNet50 and RandomForest: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Display summary of accuracies\n",
    "print(\"\\nSummary of RandomForest Model Accuracies with ResNet50 Features:\")\n",
    "for orientation, accuracy in orientation_accuracies.items():\n",
    "    print(f\"Orientation {orientation}: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab443951-9539-46d9-9777-69748edb2333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model names and corresponding accuracy values\n",
    "model_names = ['SVM', 'MobileNetV2', 'ResNet50', 'InceptionNet', 'EfficientNet']\n",
    "accuracies = [svm_accuracy, mobilenetv2_accuracy, resnet50_accuracy, inceptionnet_accuracy, efficientnet_accuracy]\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(model_names, accuracies, color=['#3498db', '#2ecc71', '#e74c3c', '#9b59b6', '#f39c12'])\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Model vs Accuracy')\n",
    "plt.ylim(0, 100)  # Setting the y-axis limit for better visual clarity\n",
    "plt.show()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Model names and corresponding accuracy values\n",
    "model_names = ['SVM', 'MobileNetV2', 'ResNet50', 'InceptionNet', 'EfficientNet']\n",
    "accuracies = [svm_accuracy, mobilenetv2_accuracy, resnet50_accuracy, inceptionnet_accuracy, efficientnet_accuracy]\n",
    "\n",
    "# Plotting the bar chart\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(model_names, accuracies, color=['#3498db', '#2ecc71', '#e74c3c', '#9b59b6', '#f39c12'])\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Model vs Accuracy')\n",
    "plt.ylim(0, 100)  # Setting the y-axis limit for better visual clarity\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ab0f905-cf4c-464f-b499-1e2c8bd178b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Model names and accuracy values for each orientation\n",
    "model_names = ['SVM', 'MobileNetV2', 'InceptionV3', 'ResNet50', 'EfficientNetB0']\n",
    "accuracy_front = [svm_front, mobilenetv2_front, inceptionv3_front, resnet50_front, efficientnetb0_front]\n",
    "accuracy_up = [svm_up, mobilenetv2_up, inceptionv3_up, resnet50_up, efficientnetb0_up]\n",
    "accuracy_down = [svm_down, mobilenetv2_down, inceptionv3_down, resnet50_down, efficientnetb0_down]\n",
    "\n",
    "# Number of models\n",
    "x = np.arange(len(model_names))\n",
    "\n",
    "# Plotting the grouped bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_width = 0.25  # Width of each bar\n",
    "\n",
    "# Create bars for each orientation\n",
    "plt.bar(x - bar_width, accuracy_front, width=bar_width, label='Front', color='#3498db')\n",
    "plt.bar(x, accuracy_up, width=bar_width, label='Up', color='#2ecc71')\n",
    "plt.bar(x + bar_width, accuracy_down, width=bar_width, label='Down', color='#e74c3c')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Model Accuracy Across Different Orientations')\n",
    "plt.xticks(x, model_names)\n",
    "plt.ylim(0, 100)  # Setting y-axis limit for visual clarity\n",
    "plt.legend(title='Orientation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d7fcf51-65a7-4521-8d44-5d6a9a8595ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy results for each model combination and orientation\n",
    "inceptionv3_svm_front, inceptionv3_svm_up, inceptionv3_svm_down = 83, 61, 61\n",
    "inceptionv3_rf_front, inceptionv3_rf_up, inceptionv3_rf_down = 65, 57, 53\n",
    "mobilenetv2_svm_front, mobilenetv2_svm_up, mobilenetv2_svm_down = 69, 49, 58\n",
    "mobilenetv2_rf_front, mobilenetv2_rf_up, mobilenetv2_rf_down = 58, 70, 47\n",
    "resnet50_svm_front, resnet50_svm_up, resnet50_svm_down = 56, 63, 43\n",
    "resnet50_rf_front, resnet50_rf_up, resnet50_rf_down = 66, 57, 62\n",
    "efficientnetb0_svm_front, efficientnetb0_svm_up, efficientnetb0_svm_down = 52, 54, 71\n",
    "efficientnetb0_rf_front, efficientnetb0_rf_up, efficientnetb0_rf_down = 67, 60, 57\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9d43ae4-9df6-4620-ad6b-a99c24e092c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Model combination names and accuracy values for each orientation\n",
    "model_combinations = [\n",
    "    'InceptionV3 + SVM', 'InceptionV3 + Random Forest',\n",
    "    'MobileNetV2 + SVM', 'MobileNetV2 + Random Forest',\n",
    "    'ResNet50 + SVM', 'ResNet50 + Random Forest',\n",
    "    'EfficientNetB0 + SVM', 'EfficientNetB0 + Random Forest'\n",
    "]\n",
    "accuracy_front = [\n",
    "    inceptionv3_svm_front, inceptionv3_rf_front,\n",
    "    mobilenetv2_svm_front, mobilenetv2_rf_front,\n",
    "    resnet50_svm_front, resnet50_rf_front,\n",
    "    efficientnetb0_svm_front, efficientnetb0_rf_front\n",
    "]\n",
    "accuracy_up = [\n",
    "    inceptionv3_svm_up, inceptionv3_rf_up,\n",
    "    mobilenetv2_svm_up, mobilenetv2_rf_up,\n",
    "    resnet50_svm_up, resnet50_rf_up,\n",
    "    efficientnetb0_svm_up, efficientnetb0_rf_up\n",
    "]\n",
    "accuracy_down = [\n",
    "    inceptionv3_svm_down, inceptionv3_rf_down,\n",
    "    mobilenetv2_svm_down, mobilenetv2_rf_down,\n",
    "    resnet50_svm_down, resnet50_rf_down,\n",
    "    efficientnetb0_svm_down, efficientnetb0_rf_down\n",
    "]\n",
    "\n",
    "# Number of model combinations\n",
    "x = np.arange(len(model_combinations))\n",
    "\n",
    "# Plotting the grouped bar chart\n",
    "plt.figure(figsize=(14, 8))\n",
    "bar_width = 0.25  # Width of each bar\n",
    "\n",
    "# Create bars for each orientation\n",
    "plt.bar(x - bar_width, accuracy_front, width=bar_width, label='Front', color='#3498db')\n",
    "plt.bar(x, accuracy_up, width=bar_width, label='Up', color='#2ecc71')\n",
    "plt.bar(x + bar_width, accuracy_down, width=bar_width, label='Down', color='#e74c3c')\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Model Combinations')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy of Model Combinations Across Different Orientations')\n",
    "plt.xticks(x, model_combinations, rotation=45, ha='right')\n",
    "plt.ylim(0, 100)  # Setting y-axis limit for visual clarity\n",
    "plt.legend(title='Orientation')\n",
    "plt.tight_layout()  # Adjust layout to fit labels and title\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac95346-90c4-4434-ba4e-771abedfb5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
